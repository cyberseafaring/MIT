{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdeab1fb",
   "metadata": {},
   "source": [
    "## 迭代器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc59582",
   "metadata": {},
   "source": [
    "迭代器是Python中一个非常重要的概念，它允许对象被迭代，即在一个序列中逐一访问元素。在Python中，迭代器遵循迭代器协议，需要实现两个方法：`__iter__()`和`__next__()`。\n",
    "\n",
    "### 迭代器协议\n",
    "\n",
    "- `__iter__()`方法返回迭代器对象本身。这是使用`for`和`in`语句时所需要的。\n",
    "- `__next__()`方法返回容器的下一个元素。当没有更多元素时，应该抛出`StopIteration`异常。\n",
    "\n",
    "### 创建自定义迭代器\n",
    "\n",
    "我们可以通过定义一个类并实现这两个方法来创建自定义迭代器。\n",
    "\n",
    "#### 示例：一个简单的计数器迭代器\n",
    "\n",
    "```python\n",
    "class Counter:\n",
    "    def __init__(self, low, high):\n",
    "        self.current = low\n",
    "        self.high = high\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current > self.high:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.current += 1\n",
    "            return self.current - 1\n",
    "\n",
    "# 使用自定义迭代器\n",
    "for c in Counter(3, 8):\n",
    "    print(c)\n",
    "```\n",
    "\n",
    "这个`Counter`类的实例是一个迭代器，它会从`low`计数到`high`。\n",
    "\n",
    "### 使用生成器简化迭代器的创建\n",
    "\n",
    "生成器是创建迭代器的简单而强大的工具，它允许你以延迟计算的方式来生成值，从而节省资源。生成器使用`yield`语句返回每个值，而不需要实现`__iter__()`和`__next__()`方法。\n",
    "\n",
    "#### 示例：使用生成器重写计数器\n",
    "\n",
    "```python\n",
    "def counter(low, high):\n",
    "    current = low\n",
    "    while current <= high:\n",
    "        yield current\n",
    "        current += 1\n",
    "\n",
    "for c in counter(3, 8):\n",
    "    print(c)\n",
    "```\n",
    "\n",
    "### 无限迭代器\n",
    "\n",
    "使用迭代器，我们还可以创建无限序列。\n",
    "\n",
    "#### 示例：无限序列生成器\n",
    "\n",
    "```python\n",
    "def infinite_sequence():\n",
    "    num = 0\n",
    "    while True:\n",
    "        yield num\n",
    "        num += 1\n",
    "\n",
    "gen = infinite_sequence()\n",
    "\n",
    "print(next(gen))  # 0\n",
    "print(next(gen))  # 1\n",
    "print(next(gen))  # 2\n",
    "# 等等，可以无限次调用next()\n",
    "```\n",
    "\n",
    "### 迭代器与可迭代对象\n",
    "\n",
    "- 可迭代对象是实现了`__iter__()`方法的对象，该方法返回一个迭代器。\n",
    "- 迭代器是实现了`__next__()`方法的对象，该方法在每次迭代中返回下一个元素。\n",
    "\n",
    "所有迭代器也都是可迭代的，但并非所有可迭代对象都是迭代器。例如，列表是可迭代的，但它不是迭代器。你可以通过调用`iter()`函数来从可迭代对象中获取一个迭代器。\n",
    "\n",
    "通过深入理解和应用迭代器，你可以更高效地处理数据序列，尤其是在处理大数据集或复杂数据流时。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b4189f",
   "metadata": {},
   "source": [
    "让我们深入探索迭代器的应用，通过实例学习如何有效利用迭代器处理数据流和实现自定义的迭代逻辑。\n",
    "\n",
    "### 应用案例1：斐波那契数列迭代器\n",
    "\n",
    "斐波那契数列是一个经典的编程问题，我们可以通过定义一个迭代器来生成斐波那契数列中的数。\n",
    "\n",
    "```python\n",
    "class Fibonacci:\n",
    "    def __init__(self):\n",
    "        self.prev, self.curr = 0, 1\n",
    "\n",
    "    def __iter__(self):\n",
    "        # 迭代器的__iter__返回自身\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        # 计算下一个斐波那契数\n",
    "        value = self.prev\n",
    "        self.prev, self.curr = self.curr, self.prev + self.curr\n",
    "        return value\n",
    "\n",
    "# 使用斐波那契迭代器\n",
    "fib = Fibonacci()\n",
    "for _, val in zip(range(10), fib):  # 限制输出前10个斐波那契数\n",
    "    print(val)\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `__init__`方法初始化前两个斐波那契数。\n",
    "- `__iter__`方法返回迭代器实例自身。\n",
    "- `__next__`方法计算并返回序列中的下一个斐波那契数。通过更新`prev`和`curr`变量来实现。\n",
    "\n",
    "### 应用案例2：生成器实现的简单数据流过滤\n",
    "\n",
    "假设我们有一个数据流，我们想过滤出其中的偶数。这可以通过一个简单的生成器来实现。\n",
    "\n",
    "```python\n",
    "def even_filter(nums):\n",
    "    for num in nums:\n",
    "        if num % 2 == 0:\n",
    "            yield num\n",
    "\n",
    "# 使用生成器\n",
    "data = range(1, 11)  # 1到10的数字\n",
    "filtered_data = even_filter(data)\n",
    "for num in filtered_data:\n",
    "    print(num)\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `even_filter`是一个生成器函数，它接收一个数字序列`nums`。\n",
    "- 通过迭代`nums`，如果数字是偶数，使用`yield`语句返回这个数字。\n",
    "- 生成器函数的调用返回一个生成器对象，我们可以迭代这个对象来获取过滤后的数据流。\n",
    "\n",
    "### 应用案例3：使用迭代器实现分页\n",
    "\n",
    "在处理大量数据时，分页是一种常见的需求。下面是一个使用迭代器实现数据分页的例子。\n",
    "\n",
    "```python\n",
    "class Paginator:\n",
    "    def __init__(self, items, page_size):\n",
    "        self.items = items\n",
    "        self.page_size = page_size\n",
    "        self.index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index >= len(self.items):\n",
    "            raise StopIteration\n",
    "        page = self.items[self.index:self.index + self.page_size]\n",
    "        self.index += self.page_size\n",
    "        return page\n",
    "\n",
    "# 使用分页器\n",
    "items = range(1, 25)  # 示例数据\n",
    "paginator = Paginator(items, 10)\n",
    "\n",
    "for page in paginator:\n",
    "    print(page)\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `Paginator`类接受一个项目列表和每页的项目数量`page_size`。\n",
    "- `__iter__`方法返回迭代器实例自身。\n",
    "- `__next__`方法返回下一页的项目。当所有项目都已返回时，抛出`StopIteration`异常以结束迭代。\n",
    "\n",
    "这些案例展示了迭代器和生成器在实现自定义迭代逻辑、处理数据流和分页等方面的强大能力和灵活性。通过合理应用，可以在各种情境下有效地管理和处理数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15cfe96",
   "metadata": {},
   "source": [
    "让我们通过一个更复杂的应用案例来进一步探索迭代器和生成器的用法，这次我们将实现一个文本文件的逐行读取器，它能够处理大文件而不会一次性将整个文件加载到内存中。\n",
    "\n",
    "### 应用案例：逐行读取大型文本文件\n",
    "\n",
    "假设你有一个非常大的文本文件，你想逐行处理其中的内容，但又不希望一次性将整个文件加载到内存中。这种情况下，可以使用生成器来逐行读取文件。\n",
    "\n",
    "```python\n",
    "def read_lines_lazy(file_path):\n",
    "    \"\"\"懒加载方式逐行读取文件内容的生成器\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            yield line.strip()\n",
    "\n",
    "# 示例使用\n",
    "file_path = 'large_file.txt'  # 假设这是一个非常大的文件\n",
    "\n",
    "for line in read_lines_lazy(file_path):\n",
    "    # 对每一行进行处理\n",
    "    print(line)\n",
    "    # 可以在这里添加处理每一行的逻辑，例如正则匹配、数据清洗等\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `read_lines_lazy`函数接受一个文件路径`file_path`作为参数。\n",
    "- 使用`with open`语句安全地打开文件，并确保文件最后被关闭。\n",
    "- `for line in file`循环逐行读取文件，这里的关键在于文件对象本身就是一个迭代器，能够懒加载逐行读取内容。\n",
    "- `yield line.strip()`返回去除了末尾空白字符的行。使用`yield`使得`read_lines_lazy`成为一个生成器函数。\n",
    "- 这种方式非常适合处理大文件，因为它一次只在内存中处理一行内容。\n",
    "\n",
    "### 进阶案例：对CSV文件进行流式处理\n",
    "\n",
    "在数据科学和数据分析中，经常需要处理大型的CSV文件。下面的例子展示了如何使用生成器逐行处理CSV文件，同时进行一些简单的数据转换。\n",
    "\n",
    "```python\n",
    "import csv\n",
    "\n",
    "def process_csv(file_path):\n",
    "    \"\"\"逐行处理CSV文件的生成器\"\"\"\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)  # 使用csv.DictReader读取CSV文件\n",
    "        for row in reader:\n",
    "            # 假设我们只关心'name'和'age'两列，并将'age'转换为整型\n",
    "            processed_row = {'name': row['name'], 'age': int(row['age'])}\n",
    "            yield processed_row\n",
    "\n",
    "# 示例使用\n",
    "csv_file_path = 'data.csv'  # 假设这是一个包含'name'和'age'列的CSV文件\n",
    "\n",
    "for row in process_csv(csv_file_path):\n",
    "    print(row)\n",
    "    # 可以在这里添加对每一行数据的进一步处理逻辑\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- 使用`csv.DictReader`读取CSV文件，它会将每行数据读取为一个字典，其中列名作为键。\n",
    "- 对每行数据进行处理，例如这里是提取特定列并进行类型转换。\n",
    "- 使用`yield`返回处理后的行，这样`process_csv`函数就成为一个生成器函数，允许逐行懒加载处理数据。\n",
    "\n",
    "通过这些案例，你可以看到迭代器和生成器在处理大型数据文件时的优势，尤其是在内存使用和处理速度方面。这些技术在数据处理、数据分析等领域非常有用，能够帮助你更高效地编写Python代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e90fb",
   "metadata": {},
   "source": [
    "## 生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35feda6",
   "metadata": {},
   "source": [
    "生成器是Python中一种非常强大的工具，它允许你以一种节省内存的方式逐步处理数据。生成器在处理大数据集或复杂计算时特别有用，因为它们一次只产生一个项，而不是一次性将所有项加载到内存中。这是通过延迟操作（lazy evaluation）实现的：生成器仅在需要时才计算下一个值。\n",
    "\n",
    "### 生成器的创建\n",
    "\n",
    "生成器可以通过两种方式创建：\n",
    "\n",
    "1. **生成器函数**：使用`yield`语句的普通函数。\n",
    "2. **生成器表达式**：类似于列表推导式，但使用圆括号。\n",
    "\n",
    "### 生成器函数\n",
    "\n",
    "生成器函数在调用时返回一个生成器对象。当迭代器要求产生下一个值时，生成器从上次离开的地方继续执行，直到遇到下一个`yield`语句。\n",
    "\n",
    "#### 示例：无限序列生成器\n",
    "\n",
    "```python\n",
    "def infinite_integers():\n",
    "    n = 0\n",
    "    while True:\n",
    "        yield n\n",
    "        n += 1\n",
    "\n",
    "gen = infinite_integers()\n",
    "print(next(gen))  # 输出: 0\n",
    "print(next(gen))  # 输出: 1\n",
    "# 可以无限次调用next()获取下一个值\n",
    "```\n",
    "\n",
    "### 生成器表达式\n",
    "\n",
    "生成器表达式看起来像列表推导式，但它返回的是一个生成器对象。它们是以延迟方式执行的，适合于迭代大数据集。\n",
    "\n",
    "#### 示例：简单的生成器表达式\n",
    "\n",
    "```python\n",
    "squares = (x*x for x in range(10))\n",
    "print(next(squares))  # 输出: 0\n",
    "print(next(squares))  # 输出: 1\n",
    "# 通过循环或其他方式可以继续迭代\n",
    "```\n",
    "\n",
    "### 生成器的优势\n",
    "\n",
    "1. **节省内存**：生成器一次只生成一个项，不需要在开始时就加载整个数据集到内存。\n",
    "2. **表示无限序列**：生成器可以表示无限的数据流，例如无限的数学序列。\n",
    "3. **管道式计算**：可以将多个生成器组合在一起，形成数据处理的管道。\n",
    "\n",
    "### 应用案例：过滤和转换数据\n",
    "\n",
    "使用生成器过滤和转换数据是非常高效的，以下是一个简单的管道式处理示例，展示了如何结合使用生成器。\n",
    "\n",
    "```python\n",
    "def integers():\n",
    "    \"\"\"生成整数序列\"\"\"\n",
    "    n = 1\n",
    "    while True:\n",
    "        yield n\n",
    "        n += 1\n",
    "\n",
    "def squared(seq):\n",
    "    \"\"\"平方数生成器\"\"\"\n",
    "    for i in seq:\n",
    "        yield i * i\n",
    "\n",
    "def negated(seq):\n",
    "    \"\"\"取反生成器\"\"\"\n",
    "    for i in seq:\n",
    "        yield -i\n",
    "\n",
    "# 创建管道\n",
    "pipeline = negated(squared(integers()))\n",
    "\n",
    "# 获取前5个处理过的值\n",
    "for _ in range(5):\n",
    "    print(next(pipeline))\n",
    "```\n",
    "\n",
    "这个示例展示了如何构建一个简单的数据处理管道，其中数据流通过一系列的转换。这种方式在处理数据流、日志文件或者大型数据集时非常有用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995a0df",
   "metadata": {},
   "source": [
    "让我们通过几个生成器的实用案例，深入探讨生成器在数据处理和性能优化中的应用。\n",
    "\n",
    "### 应用案例1：生成斐波那契数列\n",
    "\n",
    "生成器非常适合用来实现斐波那契数列，因为你可以生成无限的斐波那契数而不会用尽内存。\n",
    "\n",
    "```python\n",
    "def fibonacci():\n",
    "    a, b = 0, 1\n",
    "    while True:\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "\n",
    "# 创建斐波那契数列生成器\n",
    "fib = fibonacci()\n",
    "\n",
    "# 打印前10个斐波那契数\n",
    "for _ in range(10):\n",
    "    print(next(fib))\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `fibonacci`函数是一个生成器函数，它可以无限制地生成斐波那契数列中的数字。\n",
    "- 使用`yield`返回当前的斐波那契数，然后更新下一对值。\n",
    "- 通过`next(fib)`调用来逐个获取斐波那契数，这种方式只会在需要下一个值时才计算，节省了内存。\n",
    "\n",
    "### 应用案例2：过滤日志文件\n",
    "\n",
    "假设你有一个很大的日志文件，你想过滤出含有某个关键字的行。这个任务用生成器来实现非常高效。\n",
    "\n",
    "```python\n",
    "def read_logs(file_path):\n",
    "    \"\"\"逐行读取日志文件\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            yield line.strip()\n",
    "\n",
    "def filter_logs(lines, keyword):\n",
    "    \"\"\"过滤包含关键字的日志行\"\"\"\n",
    "    for line in lines:\n",
    "        if keyword in line:\n",
    "            yield line\n",
    "\n",
    "# 使用生成器过滤日志\n",
    "log_lines = read_logs('example.log')\n",
    "filtered_lines = filter_logs(log_lines, 'ERROR')\n",
    "\n",
    "for line in filtered_lines:\n",
    "    print(line)\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `read_logs`生成器函数逐行读取日志文件，每次`yield`一行内容。\n",
    "- `filter_logs`生成器函数进一步处理`read_logs`的输出，只`yield`包含特定关键字的行。\n",
    "- 这种方式仅加载和处理需要的行，对于处理大型日志文件非常有效。\n",
    "\n",
    "### 应用案例3：生成器表达式处理数据\n",
    "\n",
    "生成器表达式是处理数据集的简洁方式。假设我们有一组销售数据，我们想计算所有销售额的总和。\n",
    "\n",
    "```python\n",
    "sales = [342.50, 489.20, 124.99, 340.00, 450.00]  # 假设这是一组销售额数据\n",
    "\n",
    "# 使用生成器表达式计算总销售额\n",
    "total_sales = sum(sale for sale in sales if sale > 300)\n",
    "\n",
    "print(f\"Total sales over $300: {total_sales}\")\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- 这里使用了一个生成器表达式来迭代销售额列表`sales`，并过滤出大于$300的销售额。\n",
    "- `sum`函数直接计算这些销售额的总和，这个过程只遍历一次数据，非常高效。\n",
    "\n",
    "这些案例展示了生成器在数据处理中的多样性和强大功能。通过使用生成器，你可以编写出既高效又易于理解的代码，特别是在处理大量数据时。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1420f230",
   "metadata": {},
   "source": [
    "让我们探索更多复杂的生成器应用案例，这些案例将展示生成器在实现数据流处理、复杂逻辑处理以及资源管理中的高效性。\n",
    "\n",
    "### 应用案例4：批量处理数据\n",
    "\n",
    "假设你需要从数据库或大型文件中读取数据进行批处理。使用生成器可以有效地管理内存，特别是当数据量很大时。\n",
    "\n",
    "```python\n",
    "def batch_generator(data, batch_size=100):\n",
    "    \"\"\"生成指定大小的数据批次\"\"\"\n",
    "    batch = []\n",
    "    for item in data:\n",
    "        batch.append(item)\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    if batch:\n",
    "        yield batch\n",
    "\n",
    "# 模拟从数据库读取的大量数据\n",
    "data = range(1, 1005)  # 假设这是从数据库读取的1004条记录\n",
    "\n",
    "# 使用批处理生成器处理数据\n",
    "for batch in batch_generator(data, 100):\n",
    "    print(f\"Processing batch of size {len(batch)}\")\n",
    "    # 在这里添加处理批次数据的逻辑\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `batch_generator`接收一个数据集和批次大小，按批次大小`yield`数据。\n",
    "- 通过逐个收集数据项直到达到指定的批次大小，然后`yield`当前批次，这样可以分批次逐步处理大量数据而不会一次性加载到内存中。\n",
    "- 最后检查并处理剩余的数据（如果有）。\n",
    "\n",
    "### 应用案例5：链式操作处理\n",
    "\n",
    "在处理数据管道时，可以使用生成器串联多个数据处理步骤，每个步骤都以懒加载的方式处理数据。\n",
    "\n",
    "```python\n",
    "def data_source():\n",
    "    \"\"\"模拟数据源生成器\"\"\"\n",
    "    for i in range(1, 11):\n",
    "        yield i\n",
    "\n",
    "def filter_odd(data):\n",
    "    \"\"\"过滤奇数\"\"\"\n",
    "    for number in data:\n",
    "        if number % 2 == 0:\n",
    "            yield number\n",
    "\n",
    "def square(data):\n",
    "    \"\"\"计算平方\"\"\"\n",
    "    for number in data:\n",
    "        yield number * number\n",
    "\n",
    "# 构建处理管道\n",
    "pipeline = square(filter_odd(data_source()))\n",
    "\n",
    "for result in pipeline:\n",
    "    print(result)\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `data_source`生成1到10的数字。\n",
    "- `filter_odd`过滤掉奇数。\n",
    "- `square`计算每个数字的平方。\n",
    "- 这些生成器函数被链接在一起形成一个处理管道，每个函数都以懒加载的方式处理数据。\n",
    "\n",
    "### 应用案例6：资源管理\n",
    "\n",
    "生成器还可以用于管理资源，如打开文件。这种方式确保了即使在处理大文件时也不会耗尽内存。\n",
    "\n",
    "```python\n",
    "def read_large_file(file_path):\n",
    "    \"\"\"逐行读取大文件的生成器\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            yield line.strip()\n",
    "\n",
    "# 使用生成器读取大文件\n",
    "for line in read_large_file('large_file.txt'):\n",
    "    print(line)\n",
    "    # 添加处理每行的逻辑\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- 使用`with`语句确保文件正确关闭。\n",
    "- `read_large_file`生成器负责逐行读取文件，每次`yield`一行，这样文件的每一部分只在处理时才被加载到内存中。\n",
    "\n",
    "这些案例展示了生成器在数据处理和资源管理中的多样化应用。通过使用生成器，可以有效地处理大型数据集、创建复杂的数据处理管道，并管理资源，从而提高代码的效率和可读性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132caea",
   "metadata": {},
   "source": [
    "## 装饰器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4f3a4",
   "metadata": {},
   "source": [
    "### 函数装饰器\n",
    "\n",
    "函数装饰器是Python中一个强大的特性，允许你在不修改原有函数定义的情况下，增加额外的功能。装饰器本质上是一个接受函数作为参数并返回一个新函数的函数。\n",
    "\n",
    "### 简单的函数装饰器\n",
    "\n",
    "让我们从一个简单的例子开始，了解函数装饰器的基本用法。\n",
    "\n",
    "```python\n",
    "def simple_decorator(function):\n",
    "    def wrapper():\n",
    "        print(\"Something is happening before the function is called.\")\n",
    "        function()\n",
    "        print(\"Something is happening after the function is called.\")\n",
    "    return wrapper\n",
    "\n",
    "@simple_decorator\n",
    "def say_hello():\n",
    "    print(\"Hello!\")\n",
    "\n",
    "say_hello()\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `simple_decorator`是一个装饰器，它接受一个函数`function`作为参数。\n",
    "- 在`simple_decorator`内部，定义了一个嵌套函数`wrapper`，它增加了在原函数调用前后打印消息的功能。\n",
    "- 然后，`simple_decorator`返回`wrapper`函数，而不是直接调用`function`。\n",
    "- 使用`@simple_decorator`语法将`say_hello`函数“装饰”上了额外的行为。\n",
    "- 当调用`say_hello()`时，实际上是在调用`wrapper()`。\n",
    "\n",
    "### 装饰带有参数的函数\n",
    "\n",
    "装饰器也可以应用于带有参数的函数。为此，`wrapper`函数需要使用`*args`和`**kwargs`来接受任意数量的位置参数和关键字参数。\n",
    "\n",
    "```python\n",
    "def decorator_with_args(function):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(\"Arguments were:\", args, kwargs)\n",
    "        return function(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@decorator_with_args\n",
    "def greet(name, greeting=\"Hello\"):\n",
    "    print(f\"{greeting}, {name}!\")\n",
    "\n",
    "greet(\"John\", greeting=\"Hi\")\n",
    "```\n",
    "\n",
    "### 使用装饰器堆叠\n",
    "\n",
    "函数可以被多个装饰器装饰，这时装饰器的执行顺序是从最近的装饰器开始向上。\n",
    "\n",
    "```python\n",
    "def decorator_one(function):\n",
    "    def wrapper():\n",
    "        print(\"Decorator one\")\n",
    "        function()\n",
    "    return wrapper\n",
    "\n",
    "def decorator_two(function):\n",
    "    def wrapper():\n",
    "        print(\"Decorator two\")\n",
    "        function()\n",
    "    return wrapper\n",
    "\n",
    "@decorator_one\n",
    "@decorator_two\n",
    "def say_goodbye():\n",
    "    print(\"Goodbye!\")\n",
    "\n",
    "say_goodbye()\n",
    "```\n",
    "\n",
    "**执行顺序**：`decorator_two` -> `decorator_one` -> `say_goodbye`\n",
    "\n",
    "### 装饰器带有参数\n",
    "\n",
    "有时你可能需要装饰器本身接受参数。这要求再多一层嵌套：外层函数接受装饰器参数，内层函数接受被装饰的函数。\n",
    "\n",
    "```python\n",
    "def repeat(times):\n",
    "    def decorator(function):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for _ in range(times):\n",
    "                result = function(*args, **kwargs)\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@repeat(times=3)\n",
    "def greet(name):\n",
    "    print(f\"Hello, {name}!\")\n",
    "\n",
    "greet(\"Alice\")\n",
    "```\n",
    "\n",
    "### 实用装饰器\n",
    "\n",
    "装饰器在日志记录、性能测试、事务处理、缓存、权限校验和审计等方面特别有用。\n",
    "\n",
    "```python\n",
    "import functools\n",
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    \"\"\"计算函数执行时间的装饰器\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Function {func.__name__} took {end_time - start_time} seconds to complete.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def long_running_task():\n",
    "    for _ in range(1000000):\n",
    "        pass\n",
    "\n",
    "long_running_task()\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- 使用`functools.wraps`装饰`wrapper`函数，以保留原函数的元数据（如函数名）。\n",
    "- `timer`装饰器测量并打印函数执行所需的时间。\n",
    "\n",
    "装饰器提供了一种强大的模式，允许你在不修改原有代码的基础上，增加或改变函数的行为。这使得代码更加模块化，增强了代码的重用性和可读性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824aed1",
   "metadata": {},
   "source": [
    "让我们通过几个装饰器的应用案例，详细探讨它们在实际编程中的用途和实现方式。\n",
    "\n",
    "### 应用案例1：缓存装饰器\n",
    "\n",
    "在计算密集型任务中，如果一个函数会被重复调用且参数相同，使用缓存装饰器可以存储先前的计算结果，避免重复计算，从而提高效率。\n",
    "\n",
    "```python\n",
    "import functools\n",
    "\n",
    "def cache(func):\n",
    "    cached_results = {}\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args):\n",
    "        if args in cached_results:\n",
    "            return cached_results[args]\n",
    "        result = func(*args)\n",
    "        cached_results[args] = result\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@cache\n",
    "def fibonacci(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "# 使用装饰器加速斐波那契数列计算\n",
    "print(fibonacci(30))\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `cache`装饰器内部定义了一个字典`cached_results`用于存储函数的计算结果。\n",
    "- 在每次调用被装饰的函数时，`wrapper`首先检查参数对应的结果是否已经在缓存中。如果是，直接返回缓存的结果。\n",
    "- 如果缓存中没有结果，`wrapper`会调用原始函数计算结果，然后将结果存入缓存。\n",
    "- 使用`functools.wraps`保持原函数的元数据。\n",
    "\n",
    "### 应用案例2：参数验证装饰器\n",
    "\n",
    "验证函数参数类型，确保传递给函数的参数是预期类型。\n",
    "\n",
    "```python\n",
    "import functools\n",
    "\n",
    "def type_check(correct_type):\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(arg):\n",
    "            if isinstance(arg, correct_type):\n",
    "                return func(arg)\n",
    "            else:\n",
    "                print(f\"Error: Argument must be of type {correct_type.__name__}\")\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@type_check(int)\n",
    "def square(number):\n",
    "    return number ** 2\n",
    "\n",
    "print(square(2))\n",
    "square('not a number')\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `type_check`装饰器工厂接受一个类型参数`correct_type`，并返回一个装饰器。\n",
    "- 装饰器内部的`wrapper`函数检查其参数是否为正确的类型。如果不是，打印一条错误消息；如果是，调用原函数。\n",
    "- 这种方式对于确保函数使用正确的参数类型非常有用，特别是在公共API或库的开发中。\n",
    "\n",
    "### 应用案例3：性能测试装饰器\n",
    "\n",
    "记录函数执行时间，用于性能分析。\n",
    "\n",
    "```python\n",
    "import functools\n",
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"{func.__name__} ran in {end_time - start_time} secs\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def slow_function():\n",
    "    time.sleep(2)  # 模拟耗时操作\n",
    "\n",
    "slow_function()\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `timer`装饰器测量并打印被装饰函数的执行时间。\n",
    "- 在`wrapper`函数内部，记录函数执行前后的时间，计算差值即为执行时间。\n",
    "- 这个装饰器对于识别和优化慢运行的函数非常有用。\n",
    "\n",
    "通过这些案例，可以看到装饰器在缓存结果、参数校验、性能测试等方面的实际应用，它们为增强函数功能提供了一种优雅且强大的方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984ae8d",
   "metadata": {},
   "source": [
    "探索装饰器在更复杂的场景中的应用，能够帮助我们更好地理解其在实际项目中的强大用途。下面的案例将涵盖权限验证、日志记录和事务处理等高级功能。\n",
    "\n",
    "### 应用案例4：权限验证装饰器\n",
    "\n",
    "假设你正在构建一个Web应用，需要根据用户角色来限制对某些操作的访问。使用装饰器可以在不修改原始函数的情况下轻松实现权限验证。\n",
    "\n",
    "```python\n",
    "import functools\n",
    "\n",
    "# 模拟当前登录的用户\n",
    "current_user = {\"username\": \"admin\", \"role\": \"admin\"}\n",
    "\n",
    "def require_role(role):\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            if current_user.get(\"role\") != role:\n",
    "                raise Exception(\"Permission denied\")\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@require_role(\"admin\")\n",
    "def delete_user(user_id):\n",
    "    print(f\"User {user_id} deleted by {current_user['username']}\")\n",
    "\n",
    "try:\n",
    "    delete_user(1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `require_role`装饰器工厂接受一个角色名称`role`，用于指定执行装饰函数所需的用户角色。\n",
    "- 装饰器内部的`wrapper`函数在执行原始函数之前检查`current_user`的角色。如果用户角色不匹配，抛出异常拒绝访问。\n",
    "- 通过这种方式，可以轻松地在多个函数上应用权限控制，而不必在每个函数中重复权限检查的代码。\n",
    "\n",
    "### 应用案例5：日志记录装饰器\n",
    "\n",
    "在企业级应用中，日志记录是不可或缺的一部分。使用装饰器自动记录函数的调用信息和执行时间，能够提高代码的可维护性和可监控性。\n",
    "\n",
    "```python\n",
    "import functools\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def log(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logger.info(f\"Running {func.__name__} with arguments {args} and {kwargs}\")\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        logger.info(f\"Finished {func.__name__} in {end_time - start_time:.2f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@log\n",
    "def some_function(param):\n",
    "    time.sleep(1)\n",
    "    return f\"Result of {param}\"\n",
    "\n",
    "print(some_function(\"test\"))\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `log`装饰器用于记录函数的调用信息和执行时间。\n",
    "- 在函数执行前后，使用`logger.info`输出日志信息，包括函数名、参数和执行时间。\n",
    "- 这种自动化的日志记录方法简化了日志的手动编写过程，并确保了日志记录的一致性和全面性。\n",
    "\n",
    "### 应用案例6：事务处理装饰器\n",
    "\n",
    "在数据库操作中，事务的使用确保了数据的一致性和完整性。下面是一个模拟数据库事务处理的装饰器示例。\n",
    "\n",
    "```python\n",
    "import functools\n",
    "\n",
    "def transactional(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(\"Starting transaction\")\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            print(\"Committing transaction\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(\"Rolling back transaction due to error:\", e)\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "@transactional\n",
    "def update_database(record):\n",
    "    print(f\"Updating database with {record}\")\n",
    "    # 模拟错误\n",
    "    if record.get(\"error\"):\n",
    "        raise ValueError(\"Simulated error\")\n",
    "    return \"Success\"\n",
    "\n",
    "print(update_database({\"data\": \"some data\"}))\n",
    "try:\n",
    "    print(update_database({\"error\": True}))\n",
    "except ValueError as e:\n",
    "    print(\"Caught error:\", e)\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `transactional`装饰器模拟了数据库事务的开始、提交和回滚。\n",
    "- 在被装饰函数执行前后，分别打印事务开始和提交的消息。\n",
    "- 如果在执行过程中发生异常，装饰器会捕获异常，并模拟事务回滚操作。\n",
    "\n",
    "这些案例展示了装饰器在实现权限验证、日志记录、事务处理等方面的强大功能，提供了代码重用、模块化和可维护性方面的显著优势。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abde9d6",
   "metadata": {},
   "source": [
    "### 类装饰器\n",
    "\n",
    "类装饰器与函数装饰器原理相同，但它们作用于类。类装饰器主要用于修改或增强类的行为，比如添加方法、修改属性或者包装类的某些功能。它们提供了一种优雅的方式，使得在不修改类定义的情况下，还能够改变类的行为。\n",
    "\n",
    "### 基本的类装饰器\n",
    "\n",
    "类装饰器通常是一个函数，接受一个类作为参数，并返回一个新的类或者是对原类进行了修改的版本。\n",
    "\n",
    "#### 示例1：简单的类装饰器\n",
    "\n",
    "下面的装饰器为类添加了一个额外的方法`extra_method`。\n",
    "\n",
    "```python\n",
    "def add_method(cls):\n",
    "    def extra_method(self, message):\n",
    "        print(f\"Extra method says: {message}\")\n",
    "    cls.extra_method = extra_method\n",
    "    return cls\n",
    "\n",
    "@add_method\n",
    "class MyClass:\n",
    "    def my_method(self):\n",
    "        print(\"Hello from MyClass\")\n",
    "\n",
    "# 创建实例并调用新添加的方法\n",
    "my_instance = MyClass()\n",
    "my_instance.my_method()\n",
    "my_instance.extra_method(\"This is extra!\")\n",
    "```\n",
    "\n",
    "### 使用`functools.wraps`保持元数据\n",
    "\n",
    "与函数装饰器一样，类装饰器也应该使用`functools.wraps`来保持类的元数据不变。\n",
    "\n",
    "#### 示例2：包装类的初始化方法\n",
    "\n",
    "这个装饰器包装了类的`__init__`方法，以自动记录实例化时的参数。\n",
    "\n",
    "```python\n",
    "import functools\n",
    "\n",
    "def log_init(cls):\n",
    "    original_init = cls.__init__\n",
    "    \n",
    "    @functools.wraps(original_init)\n",
    "    def new_init(self, *args, **kwargs):\n",
    "        print(f\"Initializing {cls.__name__} with args {args} and kwargs {kwargs}\")\n",
    "        original_init(self, *args, **kwargs)\n",
    "        \n",
    "    cls.__init__ = new_init\n",
    "    return cls\n",
    "\n",
    "@log_init\n",
    "class MyClass:\n",
    "    def __init__(self, name, value):\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "\n",
    "# 实例化类，自动记录参数\n",
    "instance = MyClass(\"test\", 123)\n",
    "```\n",
    "\n",
    "### 类装饰器与继承\n",
    "\n",
    "类装饰器也可以用于处理类继承相关的问题，比如自动注册子类。\n",
    "\n",
    "#### 示例3：自动注册子类\n",
    "\n",
    "```python\n",
    "classes = {}\n",
    "\n",
    "def register_class(cls):\n",
    "    classes[cls.__name__] = cls\n",
    "    return cls\n",
    "\n",
    "@register_class\n",
    "class BaseClass:\n",
    "    pass\n",
    "\n",
    "@register_class\n",
    "class SubClass(BaseClass):\n",
    "    pass\n",
    "\n",
    "print(classes)  # 输出: {'BaseClass': <class '__main__.BaseClass'>, 'SubClass': <class '__main__.SubClass'>}\n",
    "```\n",
    "\n",
    "在这个例子中，`register_class`装饰器把每个装饰的类注册到一个全局字典`classes`中，便于后续引用或实例化。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "类装饰器在设计模式实现、框架开发、自动注册、资源管理和权限检查等方面非常有用。它们提供了一种在不改变类定义的前提下，增强或修改类功能的方法。\n",
    "\n",
    "类装饰器使得代码更加模块化，有助于减少重复代码，同时也增加了代码的可读性和可维护性。在设计类和组件时，合理使用类装饰器可以使得架构更加灵活和强大。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78782447",
   "metadata": {},
   "source": [
    "探索类装饰器的应用案例能够帮助我们更深入地理解其在实践中的用途。以下案例展示了类装饰器在增强类功能、实现设计模式和自动化处理中的应用。\n",
    "\n",
    "### 应用案例1：为类自动添加属性\n",
    "\n",
    "假设我们想为多个类自动添加一些通用属性，而不是在每个类定义中重复相同的代码。类装饰器可以优雅地解决这个问题。\n",
    "\n",
    "```python\n",
    "def add_attributes(**attrs):\n",
    "    def decorator(cls):\n",
    "        for name, value in attrs.items():\n",
    "            setattr(cls, name, value)\n",
    "        return cls\n",
    "    return decorator\n",
    "\n",
    "@add_attributes(version=\"1.0\", author=\"John Doe\")\n",
    "class MyClass:\n",
    "    pass\n",
    "\n",
    "# 检查新属性\n",
    "print(MyClass.version)  # 输出: 1.0\n",
    "print(MyClass.author)  # 输出: John Doe\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `add_attributes`是一个装饰器工厂，它接受任意数量的关键字参数，并返回一个装饰器。\n",
    "- 这个装饰器将传入的属性添加到目标类上，使用`setattr`实现。\n",
    "- 这种方法可以方便地为多个类添加元数据或标记属性，提高代码的复用性。\n",
    "\n",
    "### 应用案例2：单例模式实现\n",
    "\n",
    "单例模式是一种常用的设计模式，确保一个类只有一个实例，并提供一个全局访问点。使用类装饰器可以简洁地实现单例模式。\n",
    "\n",
    "```python\n",
    "def singleton(cls):\n",
    "    instances = {}\n",
    "    @functools.wraps(cls)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        if cls not in instances:\n",
    "            instances[cls] = cls(*args, **kwargs)\n",
    "        return instances[cls]\n",
    "    return wrapper\n",
    "\n",
    "@singleton\n",
    "class Database:\n",
    "    def __init__(self):\n",
    "        print(\"Loading database\")\n",
    "\n",
    "# 无论调用多少次，都只会初始化一次\n",
    "db1 = Database()\n",
    "db2 = Database()\n",
    "print(db1 is db2)  # 输出: True\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `singleton`装饰器通过维护一个`instances`字典来跟踪类的实例。\n",
    "- 当尝试创建一个新实例时，装饰器首先检查该类是否已经在`instances`中有实例，如果有，则返回现有实例，否则创建一个新实例并存储在字典中。\n",
    "- 这种方式确保了类`Database`全局只有一个实例。\n",
    "\n",
    "### 应用案例3：自动注册子类\n",
    "\n",
    "在开发插件系统或需要动态加载模块的场合，自动注册子类可以大大简化代码。\n",
    "\n",
    "```python\n",
    "class PluginRegistry(type):\n",
    "    registry = {}\n",
    "\n",
    "    def __new__(cls, name, bases, attrs):\n",
    "        new_cls = super().__new__(cls, name, bases, attrs)\n",
    "        if name != 'Plugin':\n",
    "            PluginRegistry.registry[name] = new_cls\n",
    "        return new_cls\n",
    "\n",
    "class Plugin(metaclass=PluginRegistry):\n",
    "    pass\n",
    "\n",
    "@PluginRegistry.registry\n",
    "class MyPlugin(Plugin):\n",
    "    pass\n",
    "\n",
    "print(PluginRegistry.registry)  # 输出: {'MyPlugin': <class '__main__.MyPlugin'>}\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- 在这个案例中，我们使用了一个元类`PluginRegistry`来自动注册所有`Plugin`的子类。\n",
    "- 通过在`Plugin`类定义中指定`metaclass=PluginRegistry`，确保所有继承自`Plugin`的子类在创建时都会被注册。\n",
    "- 这种自动注册机制使得管理插件或模块变得简单高效，尤其是在大型系统中。\n",
    "\n",
    "通过这些案例，我们可以看到类装饰器和元类在增强类功能、实现设计模式、以及简化代码结构方面的强大能力。正确使用这些高级特性能够使你的Python代码更加灵活和强大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9897d10b",
   "metadata": {},
   "source": [
    "为了深入探索类装饰器的高级应用，我们将通过一些更复杂的案例来展示其在实现动态功能添加、性能优化和资源管理等方面的能力。\n",
    "\n",
    "### 应用案例4：性能监控装饰器\n",
    "\n",
    "假设你想监控一个类中所有方法的执行时间，以帮助识别性能瓶颈。一个通用的类装饰器可以自动为类的每个方法添加性能监控。\n",
    "\n",
    "```python\n",
    "import time\n",
    "import types\n",
    "import functools\n",
    "\n",
    "def time_methods(cls):\n",
    "    for name, method in cls.__dict__.items():\n",
    "        if isinstance(method, types.FunctionType):\n",
    "            setattr(cls, name, timer(method))\n",
    "    return cls\n",
    "\n",
    "def timer(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Method {func.__name__} execution time: {end_time - start_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@time_methods\n",
    "class MyClass:\n",
    "    def method_slow(self):\n",
    "        time.sleep(1)\n",
    "    \n",
    "    def method_fast(self):\n",
    "        time.sleep(0.1)\n",
    "\n",
    "obj = MyClass()\n",
    "obj.method_slow()\n",
    "obj.method_fast()\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `time_methods`装饰器遍历类字典`__dict__`中的所有项，对每个函数类型的成员应用`timer`装饰器。\n",
    "- `timer`装饰器测量被装饰函数的执行时间，并在执行完成后打印。\n",
    "- 这种方法能够自动地为类中的所有方法添加性能监控，而不需要手动为每个方法添加装饰器。\n",
    "\n",
    "### 应用案例5：自动资源管理\n",
    "\n",
    "在处理文件或数据库连接时，正确地管理资源非常关键。以下示例展示如何使用类装饰器自动管理资源。\n",
    "\n",
    "```python\n",
    "def auto_close(cls):\n",
    "    original_enter = cls.__enter__\n",
    "    original_exit = cls.__exit__\n",
    "    \n",
    "    def new_enter(self):\n",
    "        return original_enter(self)\n",
    "    \n",
    "    def new_exit(self, exc_type, exc_val, exc_tb):\n",
    "        result = original_exit(self, exc_type, exc_val, exc_tb)\n",
    "        self.close()  # 自动调用资源的关闭方法\n",
    "        return result\n",
    "    \n",
    "    cls.__enter__ = new_enter\n",
    "    cls.__exit__ = new_exit\n",
    "    return cls\n",
    "\n",
    "@auto_close\n",
    "class ManagedResource:\n",
    "    def __enter__(self):\n",
    "        print(\"Resource opened.\")\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        print(\"Resource exit.\")\n",
    "    \n",
    "    def close(self):\n",
    "        print(\"Resource closed.\")\n",
    "\n",
    "with ManagedResource() as resource:\n",
    "    print(\"Using resource.\")\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `auto_close`装饰器修改了类的`__enter__`和`__exit__`方法，以确保资源使用完毕后自动关闭。\n",
    "- 通过装饰器模式，可以将资源管理逻辑集中处理，避免遗忘关闭资源。\n",
    "\n",
    "### 应用案例6：事件驱动编程\n",
    "\n",
    "在事件驱动的应用中，类装饰器可以用来自动注册事件处理器，简化事件订阅模式的实现。\n",
    "\n",
    "```python\n",
    "event_handlers = {}\n",
    "\n",
    "def event_handler(event):\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return func(*args, **kwargs)\n",
    "        event_handlers[event] = wrapper\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@event_handler('LOGIN')\n",
    "def handle_login(user):\n",
    "    print(f\"{user} logged in.\")\n",
    "\n",
    "# 模拟事件触发\n",
    "event = 'LOGIN'\n",
    "if event in event_handlers:\n",
    "    event_handlers[event]('John Doe')\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `event_handler`装饰器工厂接受一个事件类型作为参数，并返回一个装饰器。\n",
    "- 被装饰的函数将自动注册为相应事件的处理器。\n",
    "- 这种模式非常适合实现插件系统、事件监听器或回调函数的自动注册。\n",
    "\n",
    "这些案例展示了类装饰器在不同场景下的应用，从性能监控到资源管理，再到事件处理，展现了其在提高代码质量、简化架构设计和优化性能方面的巨大潜力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b75d05",
   "metadata": {},
   "source": [
    "## 上下文管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c321172",
   "metadata": {},
   "source": [
    "上下文管理器在Python中是处理资源的一种优雅方式，特别是对于那些需要显式地分配和释放资源的操作，如文件操作、网络连接和数据库会话。上下文管理器使用`with`语句，能够确保即使在发生错误时资源也能被正确地释放。\n",
    "\n",
    "### 上下文管理器的工作原理\n",
    "\n",
    "上下文管理器依赖于Python的`__enter__`和`__exit__`魔法方法。当进入`with`语句块时，会调用上下文管理器的`__enter__`方法；当离开`with`语句块时，无论是正常退出还是异常退出，都会调用`__exit__`方法。\n",
    "\n",
    "### 实现上下文管理器\n",
    "\n",
    "上下文管理器可以通过定义一个类并实现这两个方法来创建。\n",
    "\n",
    "#### 示例1：文件操作的上下文管理器\n",
    "\n",
    "```python\n",
    "class FileOpener:\n",
    "    def __init__(self, filename, mode):\n",
    "        self.file = open(filename, mode)\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self.file\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.file.close()\n",
    "\n",
    "# 使用自定义的文件上下文管理器\n",
    "with FileOpener('test.txt', 'w') as file:\n",
    "    file.write('Hello, world!')\n",
    "\n",
    "# 文件已被自动关闭\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `FileOpener`类在`__init__`方法中打开文件，在`__enter__`方法中返回文件对象，在`__exit__`方法中关闭文件。\n",
    "- 使用`with`语句自动管理文件的打开和关闭过程，无需手动调用`close`方法。\n",
    "\n",
    "### 使用`contextlib`模块简化上下文管理器\n",
    "\n",
    "Python的`contextlib`模块提供了一些工具，使得实现上下文管理器更加简单。\n",
    "\n",
    "#### 示例2：使用`contextlib`的上下文管理器\n",
    "\n",
    "```python\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def file_opener(filename, mode):\n",
    "    file = open(filename, mode)\n",
    "    try:\n",
    "        yield file\n",
    "    finally:\n",
    "        file.close()\n",
    "\n",
    "# 使用装饰器创建的上下文管理器\n",
    "with file_opener('test.txt', 'w') as file:\n",
    "    file.write('Hello again, world!')\n",
    "\n",
    "# 文件已被自动关闭\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `@contextmanager`装饰器允许你通过生成器的方式定义一个上下文管理器。\n",
    "- 在`yield`之前的代码相当于`__enter__`方法中的代码，在`yield`之后的代码相当于`__exit__`方法中的代码。\n",
    "\n",
    "### 应用场景\n",
    "\n",
    "上下文管理器广泛应用于资源管理，确保资源如文件、网络连接或数据库会话等在使用完成后能够被正确释放。它们还可以用于事务处理、锁管理、临时更改日志级别等场景，提供了代码的清晰结构和异常安全的资源管理方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64cb1d",
   "metadata": {},
   "source": [
    "让我们探索一些上下文管理器的实际应用案例，以深入理解其在资源管理和程序执行流控制中的作用。\n",
    "\n",
    "### 应用案例1：管理数据库连接\n",
    "\n",
    "上下文管理器可以确保数据库连接在使用后正确关闭，避免悬挂连接或资源泄漏。\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def db_connect(db_name):\n",
    "    connection = sqlite3.connect(db_name)\n",
    "    try:\n",
    "        yield connection\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "# 使用上下文管理器操作数据库\n",
    "with db_connect('example.db') as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('CREATE TABLE IF NOT EXISTS messages (content TEXT)')\n",
    "    cursor.execute('INSERT INTO messages (content) VALUES (?)', ('Hello, World!',))\n",
    "    conn.commit()\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `db_connect`上下文管理器使用`@contextmanager`装饰器，确保数据库连接在退出`with`块时关闭。\n",
    "- 在`try`块内，`yield`返回数据库连接对象，允许在`with`块内进行数据库操作。\n",
    "- 无论数据库操作是否成功，`finally`块确保数据库连接最终关闭。\n",
    "\n",
    "### 应用案例2：临时修改日志级别\n",
    "\n",
    "在某个代码块中临时更改日志级别，执行完毕后恢复原来的级别。\n",
    "\n",
    "```python\n",
    "import logging\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def log_level(level, name):\n",
    "    logger = logging.getLogger(name)\n",
    "    old_level = logger.getEffectiveLevel()\n",
    "    logger.setLevel(level)\n",
    "    try:\n",
    "        yield logger\n",
    "    finally:\n",
    "        logger.setLevel(old_level)\n",
    "\n",
    "# 使用上下文管理器临时设置日志级别\n",
    "with log_level(logging.DEBUG, 'my-logger') as logger:\n",
    "    logger.debug('This will be logged due to the DEBUG level.')\n",
    "    logger.info('This will also be logged.')\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `log_level`上下文管理器临时更改指定日志器的日志级别，并在退出`with`块时恢复。\n",
    "- 这对于调试特定代码段非常有用，无需更改全局日志配置。\n",
    "\n",
    "### 应用案例3：资源锁定和释放\n",
    "\n",
    "上下文管理器在并发编程中管理锁定资源，确保资源在使用后被释放，是非常有用的。\n",
    "\n",
    "```python\n",
    "from threading import Lock\n",
    "from contextlib import contextmanager\n",
    "\n",
    "lock = Lock()\n",
    "\n",
    "@contextmanager\n",
    "def acquire_lock(l):\n",
    "    l.acquire()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        l.release()\n",
    "\n",
    "# 使用上下文管理器安全地锁定和释放锁\n",
    "with acquire_lock(lock):\n",
    "    # 安全执行需要锁定的操作\n",
    "    print(\"Critical section with lock\")\n",
    "```\n",
    "\n",
    "**注解**：\n",
    "- `acquire_lock`上下文管理器通过`Lock`对象管理资源的锁定和释放。\n",
    "- 这种方法可以避免忘记释放锁或异常导致的锁未释放问题，保证了代码的安全性。\n",
    "\n",
    "通过这些案例，我们可以看到上下文管理器在不同场景下如何有效地管理资源，确保资源的正确使用和释放。它不仅提高了代码的可读性和可维护性，还增强了程序的健壮性和安全性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b725afe",
   "metadata": {},
   "source": [
    "探索更复杂的上下文管理器应用案例可以帮助我们理解其在实际开发中的广泛用途。以下案例涉及到更高级的资源管理和控制流的使用场景。\n",
    "\n",
    "### 应用案例4：性能监控上下文管理器\n",
    "\n",
    "假设你需要监控特定代码段的执行时间以优化性能，可以通过上下文管理器实现一个简单的性能监控工具。\n",
    "\n",
    "```python\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def monitor_performance(label):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        end = time.time()\n",
    "        print(f\"{label}: {end - start:.4f} seconds\")\n",
    "\n",
    "# 使用性能监控上下文管理器\n",
    "with monitor_performance(\"Loading data\"):\n",
    "    # 模拟数据加载过程\n",
    "    time.sleep(1)\n",
    "\n",
    "with monitor_performance(\"Processing data\"):\n",
    "    # 模拟数据处理过程\n",
    "    time.sleep(2)\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `monitor_performance`上下文管理器测量并打印包含在`with`块中代码的执行时间。\n",
    "- 在进入`with`块时记录当前时间，在退出时计算并打印耗时，这对于性能调优非常有用。\n",
    "\n",
    "### 应用案例5：事务控制上下文管理器\n",
    "\n",
    "在数据库操作中，事务控制是确保数据一致性和完整性的关键机制。以下示例展示如何使用上下文管理器简化事务控制逻辑。\n",
    "\n",
    "```python\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def transaction(db_connection):\n",
    "    cursor = db_connection.cursor()\n",
    "    try:\n",
    "        yield cursor\n",
    "        db_connection.commit()\n",
    "    except Exception:\n",
    "        db_connection.rollback()\n",
    "        raise\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "# 使用事务控制上下文管理器\n",
    "with transaction(my_db_connection) as cursor:\n",
    "    cursor.execute(\"UPDATE table SET column = value WHERE condition\")\n",
    "    # 更多数据库操作...\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `transaction`上下文管理器开始时创建一个数据库游标，然后尝试执行`with`块中的数据库操作。\n",
    "- 如果操作成功，提交事务；如果发生异常，回滚事务并重新抛出异常以便调用者处理。\n",
    "- 这种模式确保了数据库操作的原子性，简化了事务控制代码的编写。\n",
    "\n",
    "### 应用案例6：临时修改系统状态\n",
    "\n",
    "某些情况下，你可能需要临时修改系统的状态或环境设置，并在操作完成后恢复原状。这可以通过上下文管理器实现。\n",
    "\n",
    "```python\n",
    "import os\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def temporary_change_dir(destination):\n",
    "    current_dir = os.getcwd()\n",
    "    os.chdir(destination)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        os.chdir(current_dir)\n",
    "\n",
    "# 使用上下文管理器临时改变当前工作目录\n",
    "with temporary_change_dir(\"/tmp\"):\n",
    "    # 在/tmp目录下执行操作\n",
    "    pass\n",
    "# 自动回到原工作目录\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `temporary_change_dir`上下文管理器在进入`with`块时改变当前工作目录，并在退出时恢复。\n",
    "- 这对于需要在特定目录下执行操作的脚本或应用非常有用，避免了在代码中手动切换和恢复工作目录。\n",
    "\n",
    "这些案例展示了上下文管理器在性能监控、事务控制、临时修改系统状态等方面的强大功能。通过合理利用上下文管理器，可以写出更加清晰、健壮和易于维护的代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20951061",
   "metadata": {},
   "source": [
    "## 并发编程\n",
    "\n",
    "线程，进程，协程，asyncio模块。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12190e",
   "metadata": {},
   "source": [
    "并发编程是编程领域中一个复杂但强大的概念，它允许多个任务同时进行，以提高应用程序的性能和响应速度。在Python中，线程（Thread）是实现并发编程的基本方式之一。线程允许程序同时执行多个任务，它们共享同一进程的内存空间，这使得线程间的数据共享和通信相对简单。\n",
    "\n",
    "### Python中的线程\n",
    "\n",
    "Python标准库`threading`提供了丰富的线程操作功能，包括线程的创建、启动、同步（如锁和条件变量）等。\n",
    "\n",
    "#### 创建和启动线程\n",
    "\n",
    "在Python中创建线程最直接的方式是实例化`threading.Thread`类，并将目标函数传递给它。\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "def task():\n",
    "    print(\"Executing our Task on a separate thread.\")\n",
    "\n",
    "# 创建线程\n",
    "thread = threading.Thread(target=task)\n",
    "\n",
    "# 启动线程\n",
    "thread.start()\n",
    "\n",
    "# 等待线程完成\n",
    "thread.join()\n",
    "```\n",
    "\n",
    "#### 线程间的数据共享和同步\n",
    "\n",
    "线程间共享内存和数据是线程的一个重要特性，但这也引入了数据竞争和状态不一致的问题。为了解决这些问题，需要使用同步原语，如锁（Lock）。\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "# 创建一个锁对象\n",
    "lock = threading.Lock()\n",
    "\n",
    "balance = 0\n",
    "\n",
    "def deposit(amount):\n",
    "    global balance\n",
    "    with lock:\n",
    "        print(f\"Depositing {amount}\")\n",
    "        balance += amount\n",
    "\n",
    "def withdraw(amount):\n",
    "    global balance\n",
    "    with lock:\n",
    "        print(f\"Withdrawing {amount}\")\n",
    "        balance -= amount\n",
    "\n",
    "# 创建线程\n",
    "t1 = threading.Thread(target=deposit, args=(100,))\n",
    "t2 = threading.Thread(target=withdraw, args=(50,))\n",
    "\n",
    "# 启动线程\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# 等待线程完成\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(f\"Final balance: {balance}\")\n",
    "```\n",
    "\n",
    "### 线程局部数据（Thread Local Data）\n",
    "\n",
    "线程局部数据是线程的一个强大特性，允许为每个线程保存一个独立的数据副本。\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "# 创建线程局部数据\n",
    "thread_local = threading.local()\n",
    "\n",
    "def task():\n",
    "    # 为每个线程设置不同的数据\n",
    "    thread_local.data = f\"Data for {threading.current_thread().name}\"\n",
    "    print(thread_local.data)\n",
    "\n",
    "# 创建多个线程\n",
    "for i in range(3):\n",
    "    t = threading.Thread(target=task, name=f\"Thread-{i}\")\n",
    "    t.start()\n",
    "```\n",
    "\n",
    "### GIL（全局解释器锁）\n",
    "\n",
    "Python的线程虽然是真正的系统级线程，但由于CPython解释器的全局解释器锁（GIL）的存在，同一时刻只能有一个线程执行Python字节码。这意味着在CPU密集型任务中，多线程可能不会带来性能上的提升，反而因为线程切换的开销而降低性能。然而，在I/O密集型任务中，多线程仍然是提高性能的有效方式。\n",
    "\n",
    "### 小结\n",
    "\n",
    "Python的`threading`模块提供了一个高级的API来创建和管理线程。线程可以共享数据和状态，但这也需要注意同步问题。线程局部数据允许每个线程有自己的数据副本，避免了数据共享的问题。然而，GIL的存在限制了线程在CPU密集型任务中的性能，但在I/O密集型应用中，使用线程可以有效地提高程序的并发性和响应速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc364a",
   "metadata": {},
   "source": [
    "探索线程在实际编程中的应用可以帮助我们更好地理解并发编程的概念和实践。以下案例展示了线程的不同用途和实现方式。\n",
    "\n",
    "### 应用案例1：并发执行任务\n",
    "\n",
    "假设我们有一个任务列表，每个任务都需要一些时间来执行。我们可以使用线程并发执行这些任务，以减少总的执行时间。\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def perform_task(task_id, duration):\n",
    "    print(f\"Task {task_id} started\")\n",
    "    time.sleep(duration)\n",
    "    print(f\"Task {task_id} completed\")\n",
    "\n",
    "tasks = [(1, 2), (2, 3), (3, 1)]  # 每个元组包含任务ID和执行时间\n",
    "\n",
    "threads = []\n",
    "\n",
    "# 创建线程并启动\n",
    "for task_id, duration in tasks:\n",
    "    thread = threading.Thread(target=perform_task, args=(task_id, duration))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# 等待所有线程完成\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"All tasks completed\")\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `perform_task`函数模拟了执行任务，其中`task_id`是任务的标识，`duration`是任务执行的时间。\n",
    "- 对于任务列表中的每个任务，我们创建一个线程，并将任务ID和执行时间传递给`perform_task`函数。\n",
    "- 使用`thread.start()`启动线程，然后使用`thread.join()`等待所有线程完成，确保主线程最后退出。\n",
    "\n",
    "### 应用案例2：使用锁解决数据竞争\n",
    "\n",
    "当多个线程需要访问和修改共享数据时，为了防止数据竞争和状态不一致，我们可以使用锁（Lock）。\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "class BankAccount:\n",
    "    def __init__(self):\n",
    "        self.balance = 100  # 初始余额\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def update(self, transaction, amount):\n",
    "        print(f\"{transaction} started\")\n",
    "        with self.lock:\n",
    "            new_balance = self.balance + amount\n",
    "            # 模拟交易处理时间\n",
    "            time.sleep(0.1)\n",
    "            self.balance = new_balance\n",
    "        print(f\"{transaction} ended\")\n",
    "\n",
    "account = BankAccount()\n",
    "\n",
    "# 创建线程进行存取款\n",
    "deposit = threading.Thread(target=account.update, args=('Deposit', 50))\n",
    "withdrawal = threading.Thread(target=account.update, args=('Withdrawal', -150))\n",
    "\n",
    "deposit.start()\n",
    "withdrawal.start()\n",
    "\n",
    "deposit.join()\n",
    "withdrawal.join()\n",
    "\n",
    "print(f\"Final balance: {account.balance}\")\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `BankAccount`类包含了一个简单的银行账户模型，其中`update`方法用于更新账户余额。\n",
    "- `update`方法使用了锁来确保在修改余额时不会由于多个线程同时访问导致数据竞争。\n",
    "- 通过`with self.lock`获取锁，在修改完成后自动释放，保证了交易的原子性。\n",
    "\n",
    "### 应用案例3：线程间通信\n",
    "\n",
    "线程间的通信通常使用条件变量（Condition），这是一种更高级的线程同步机制。\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import collections\n",
    "\n",
    "class SimpleQueue:\n",
    "    def __init__(self):\n",
    "        self.elements = collections.deque()\n",
    "        self.condition = threading.Condition()\n",
    "\n",
    "    def put(self, element):\n",
    "        with self.condition:\n",
    "            self.elements.append(element)\n",
    "            self.condition.notify()\n",
    "\n",
    "    def get(self):\n",
    "        with self.condition:\n",
    "            while not self.elements:\n",
    "                self.condition.wait()\n",
    "            return self.elements.popleft()\n",
    "\n",
    "queue = SimpleQueue()\n",
    "\n",
    "def producer():\n",
    "    for i in range(5):\n",
    "        print(f\"Producing {i}\")\n",
    "        queue.put(i)\n",
    "        time.sleep(1)\n",
    "\n",
    "def consumer():\n",
    "    for _ in range(5):\n",
    "        item = queue.get()\n",
    "        print(f\"Consuming {item}\")\n",
    "\n",
    "producer_thread = threading.Thread(target=producer)\n",
    "consumer_thread = threading.Thread(target=consumer)\n",
    "\n",
    "producer_thread.start()\n",
    "consumer_thread.start()\n",
    "\n",
    "producer_thread.join()\n",
    "consumer_thread.join()\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `SimpleQueue`类实现了一个线程安全的队列，使用条件变量来同步对队列的访问。\n",
    "- 生产者线程使用`put`方法添加元素到队列，消费者线程使用`get`方法从队列中取出元素。\n",
    "- 当队列为空时，消费者线程会在`self.condition.wait()`处等待，直到生产者线程添加了新元素并调用`self.condition.notify()`。\n",
    "\n",
    "这些案例展示了线程在并发执行任务、解决数据竞争和线程间通信中的应用。合理使用线程可以显著提高程序的性能和响应速度，但也需要注意同步和数据竞争的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73855a7d",
   "metadata": {},
   "source": [
    "深入探讨并发编程，我们将通过一些复杂的应用案例来进一步展示线程的高级用法，包括工作线程池的使用、线程安全的数据结构，以及复杂的线程间同步。\n",
    "\n",
    "### 应用案例4：使用线程池处理任务\n",
    "\n",
    "对于大量的小任务，创建和销毁线程的开销可能会影响性能。线程池（ThreadPoolExecutor）提供了一个线程复用的解决方案，可以提高程序的效率和响应性。\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "def task(n):\n",
    "    print(f\"Processing {n}\")\n",
    "    time.sleep(2)\n",
    "    print(f\"Task {n} completed\")\n",
    "\n",
    "# 创建一个线程池，池中最多三个线程\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    tasks = [executor.submit(task, n) for n in range(1, 6)]\n",
    "\n",
    "print(\"All tasks have been queued.\")\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- 使用`ThreadPoolExecutor`创建一个线程池，`max_workers`参数指定了池中最多可以有多少个线程。\n",
    "- `executor.submit`方法用于提交任务到线程池。这个方法立即返回，任务会在后台线程中执行。\n",
    "- 使用`with`语句可以确保线程池在所有任务完成后自动关闭。\n",
    "\n",
    "### 应用案例5：线程安全的计数器\n",
    "\n",
    "在多线程环境下，如果多个线程同时修改同一个变量，可能会导致数据不一致。以下是一个线程安全的计数器实现。\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "class ThreadSafeCounter:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def increment(self):\n",
    "        with self.lock:\n",
    "            self.value += 1\n",
    "\n",
    "    def get(self):\n",
    "        with self.lock:\n",
    "            return self.value\n",
    "\n",
    "counter = ThreadSafeCounter()\n",
    "\n",
    "def increment_counter():\n",
    "    for _ in range(1000):\n",
    "        counter.increment()\n",
    "\n",
    "threads = [threading.Thread(target=increment_counter) for _ in range(10)]\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(f\"Counter value: {counter.get()}\")\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `ThreadSafeCounter`类使用了`Lock`对象来同步对`value`的访问，确保了`increment`和`get`方法的线程安全。\n",
    "- 创建了10个线程，每个线程都对计数器执行了1000次增加操作。\n",
    "- 使用`lock`确保了即使在多线程环境下，`value`的修改也是原子的，防止了竞态条件。\n",
    "\n",
    "### 应用案例6：条件变量实现生产者消费者模式\n",
    "\n",
    "生产者消费者模式是并发编程中常见的模式之一，用于协调生产者和消费者之间的工作流程，避免资源的过度生产或消费。\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import collections\n",
    "import time\n",
    "\n",
    "class ProducerConsumerQueue:\n",
    "    def __init__(self, capacity):\n",
    "        self.queue = collections.deque(maxlen=capacity)\n",
    "        self.condition = threading.Condition()\n",
    "\n",
    "    def produce(self, item):\n",
    "        with self.condition:\n",
    "            while len(self.queue) == self.queue.maxlen:\n",
    "                self.condition.wait()\n",
    "            self.queue.append(item)\n",
    "            self.condition.notify()\n",
    "\n",
    "    def consume(self):\n",
    "        with self.condition:\n",
    "            while not self.queue:\n",
    "                self.condition.wait()\n",
    "            item = self.queue.popleft()\n",
    "            self.condition.notify()\n",
    "            return item\n",
    "\n",
    "queue = ProducerConsumerQueue(5)\n",
    "\n",
    "def producer():\n",
    "    for i in range(20):\n",
    "        queue.produce(i)\n",
    "        print(f\"Produced {i}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "def consumer():\n",
    "    for _ in range(20):\n",
    "        item = queue.consume()\n",
    "        print(f\"Consumed {item}\")\n",
    "        time.sleep(2)\n",
    "\n",
    "producer_thread = threading.Thread(target=producer)\n",
    "consumer_thread = threading.Thread(target=consumer)\n",
    "\n",
    "producer_thread.start()\n",
    "consumer_thread.start()\n",
    "\n",
    "producer_thread.join()\n",
    "consumer_thread.join()\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `ProducerConsumerQueue`类使用了`Condition`对象来同步生产者和消费者对队列的访问。\n",
    "- 生产者在队列满时等待，消费者在队列空时等待，通过`condition.wait()`挂起当前线程直到被`condition.notify()`唤醒。\n",
    "- 这个模式有效地协调了生产者和\n",
    "\n",
    "消费者之间的工作，避免了资源的浪费和竞争。\n",
    "\n",
    "通过这些案例，我们展示了线程在实现任务并行处理、保证线程安全以及实现复杂同步模式中的应用。正确使用线程和线程同步机制，可以有效地解决并发编程中的各种挑战。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a1372c",
   "metadata": {},
   "source": [
    "## 进程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e3b061",
   "metadata": {},
   "source": [
    "进程是操作系统分配资源和调度的基本单位。与线程相比，每个进程都有自己独立的内存空间，这使得进程间通信比线程间通信更加复杂，但进程间相互隔离也意味着一个进程崩溃不会直接影响到其他进程。Python中的`multiprocessing`模块提供了一个简单的方法来创建多进程，使得并发编程不仅限于线程。\n",
    "\n",
    "### Python中的进程\n",
    "\n",
    "`multiprocessing`模块提供了与`threading`模块类似的API，用于支持进程的创建、执行、同步以及通信。\n",
    "\n",
    "#### 创建和启动进程\n",
    "\n",
    "```python\n",
    "from multiprocessing import Process\n",
    "\n",
    "def print_func(continent='Asia'):\n",
    "    print(f'The name of continent is : {continent}')\n",
    "\n",
    "if __name__ == \"__main__\":  # Windows平台下必须在这样的保护块中启动进程\n",
    "    names = ['America', 'Europe', 'Africa']\n",
    "    procs = []\n",
    "    \n",
    "    # 创建进程\n",
    "    for name in names:\n",
    "        proc = Process(target=print_func, args=(name,))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "    \n",
    "    # 等待所有进程完成\n",
    "    for proc in procs:\n",
    "        proc.join()\n",
    "```\n",
    "\n",
    "#### 进程间通信\n",
    "\n",
    "`multiprocessing`模块提供了多种进程间通信（IPC）的方式，如管道（Pipes）和队列（Queues）。\n",
    "\n",
    "```python\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def square(numbers, queue):\n",
    "    for i in numbers:\n",
    "        queue.put(i * i)\n",
    "\n",
    "def make_negative(numbers, queue):\n",
    "    for i in numbers:\n",
    "        queue.put(-1 * i)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    numbers = range(1, 6)\n",
    "    queue = Queue()\n",
    "    \n",
    "    p1 = Process(target=square, args=(numbers, queue))\n",
    "    p2 = Process(target=make_negative, args=(numbers, queue))\n",
    "    \n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    \n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    \n",
    "    while not queue.empty():\n",
    "        print(queue.get())\n",
    "```\n",
    "\n",
    "#### 进程池\n",
    "\n",
    "对于大量的独立任务，使用进程池可以有效管理进程的创建和销毁，提高资源利用率。\n",
    "\n",
    "```python\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def square(number):\n",
    "    return number * number\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    numbers = range(10)\n",
    "    pool = Pool()\n",
    "    \n",
    "    # 使用map()并行计算\n",
    "    results = pool.map(square, numbers)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    print(results)\n",
    "```\n",
    "\n",
    "### 全局解释器锁（GIL）和进程\n",
    "\n",
    "Python的全局解释器锁（GIL）限制了同一时刻只有一个线程可以执行Python字节码，这意味着多线程在执行CPU密集型任务时可能不会得到性能提升。使用多进程可以绕过GIL的限制，因为每个进程都有自己的Python解释器和内存空间。\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 进程间通信比线程间通信成本更高，因为它们不共享内存空间。\n",
    "- 在Windows上创建进程时，必须在`if __name__ == \"__main__\":`保护块内启动进程，以避免无限递归创建进程。\n",
    "- 使用多进程时，需要特别注意资源管理和同步，以避免竞态条件和死锁。\n",
    "\n",
    "进程是实现Python并发编程的有力工具，特别适合CPU密集型任务。正确使用`multiprocessing`模块，可以显著提高程序的性能和响应速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd797aa7",
   "metadata": {},
   "source": [
    "探索`multiprocessing`模块的应用案例能够帮助我们更深入地理解Python中进程的使用和并发编程的实践。下面的案例涵盖了进程的创建、进程间通信和进程池的使用，展示了多进程在解决实际问题时的强大能力。\n",
    "\n",
    "### 应用案例1：并行数据处理\n",
    "\n",
    "当面对大量数据需要进行独立且相同的处理时，使用多进程可以显著加快处理速度。\n",
    "\n",
    "```python\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def process_data(data):\n",
    "    # 假设这是一个计算密集型的数据处理函数\n",
    "    return data * data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_to_process = range(10000)\n",
    "    with Pool(4) as p:  # 创建拥有4个进程的进程池\n",
    "        results = p.map(process_data, data_to_process)\n",
    "    print(results[:10])  # 打印前10个结果作为示例\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- 使用`Pool`创建一个进程池，参数指定了池中进程的数量。\n",
    "- `Pool.map`方法类似于内置的`map`函数，但它会并行地在多个进程中执行`process_data`函数。\n",
    "- 这种方法适用于数据集较大且每个数据项处理相对独立的场景。\n",
    "\n",
    "### 应用案例2：进程间通信 - 使用队列\n",
    "\n",
    "多进程间的数据共享和通信可以通过`Queue`实现，它是一个线程和进程安全的队列。\n",
    "\n",
    "```python\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def producer(queue):\n",
    "    for i in range(5):\n",
    "        queue.put(f'Product {i}')\n",
    "        print(f'Produced Product {i}')\n",
    "\n",
    "def consumer(queue):\n",
    "    for _ in range(5):\n",
    "        product = queue.get()\n",
    "        print(f'Consumed {product}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    queue = Queue()\n",
    "    p = Process(target=producer, args=(queue,))\n",
    "    c = Process(target=consumer, args=(queue,))\n",
    "    \n",
    "    p.start()\n",
    "    c.start()\n",
    "    \n",
    "    p.join()\n",
    "    c.join()\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `Queue`用于进程间通信，生产者进程通过`queue.put()`发送数据，消费者进程通过`queue.get()`接收数据。\n",
    "- 这种生产者-消费者模型是多进程应用中常见的通信模式。\n",
    "\n",
    "### 应用案例3：使用共享内存\n",
    "\n",
    "对于需要共享大量数据的场景，使用`multiprocessing`模块的共享内存特性可以避免数据的序列化和反序列化开销，提高效率。\n",
    "\n",
    "```python\n",
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "def square(number, result, index):\n",
    "    result[index] = number * number\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    numbers = [1, 2, 3, 4]\n",
    "    result = Array('i', 4)  # 创建一个共享数组\n",
    "    \n",
    "    processes = [Process(target=square, args=(numbers[i], result, i)) for i in range(4)]\n",
    "    \n",
    "    for p in processes:\n",
    "        p.start()\n",
    "        \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "        \n",
    "    print(result[:])  # 输出: [1, 4, 9, 16]\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `Value`和`Array`类提供了创建共享内存的方式，这些对象可以在多个进程之间共享。\n",
    "- 在这个示例中，每个进程计算一个数字的平方，并将结果存储在共享数组`result`中。\n",
    "- 这种方法适用于多个进程需要访问和修改同一数据集的场景。\n",
    "\n",
    "通过这些案例，我们可以看到`multiprocessing`模块在并行数据处理、进程间通信以及共享内存管理方面的强大功能。正确利用多进程可以有效地解决并发编程中的各种挑战，提升程序的性能和响应速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235413e1",
   "metadata": {},
   "source": [
    "深入探索`multiprocessing`模块的高级应用，可以揭示Python中多进程编程的潜力，特别是在解决那些需要大量计算资源的问题时。以下案例将展示多进程的复杂应用，包括动态进程池管理、进程间使用管道通信以及利用共享内存进行大规模数据处理。\n",
    "\n",
    "### 应用案例4：动态任务分配给进程池\n",
    "\n",
    "动态分配任务给进程池是并发编程中的一个常见需求，特别是当任务的数量事先不确定或者各任务完成时间差异较大时。\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "def compute_some_thing(data):\n",
    "    time.sleep(1)  # 模拟耗时操作\n",
    "    return data * data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_to_process = range(1, 11)\n",
    "    results = []\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures = {executor.submit(compute_some_thing, data): data for data in data_to_process}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            print(f\"Result: {result}\")\n",
    "            results.append(result)\n",
    "\n",
    "    print(\"All tasks completed\")\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- 使用`ProcessPoolExecutor`创建一个拥有固定数量工作进程的进程池。\n",
    "- `executor.submit`非阻塞地提交任务到进程池并立即返回一个`Future`对象。\n",
    "- `as_completed`用于迭代完成的任务，无论它们的提交顺序如何，确保随着任务完成立即处理结果。\n",
    "- 这种方式对于负载不均或任务动态生成的情况非常有用。\n",
    "\n",
    "### 应用案例5：进程间使用管道进行双向通信\n",
    "\n",
    "管道（Pipe）是`multiprocessing`提供的另一种进程间通信机制，适用于少量进程之间的大量数据交换。\n",
    "\n",
    "```python\n",
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def sender(pipe):\n",
    "    _, send_pipe = pipe\n",
    "    for i in range(5):\n",
    "        send_pipe.send(f\"Message {i}\")\n",
    "    send_pipe.close()\n",
    "\n",
    "def receiver(pipe):\n",
    "    recv_pipe, _ = pipe\n",
    "    while True:\n",
    "        message = recv_pipe.recv()\n",
    "        if message == \"END\":\n",
    "            break\n",
    "        print(f\"Received: {message}\")\n",
    "    recv_pipe.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    recv_pipe, send_pipe = Pipe(duplex=False)\n",
    "    p1 = Process(target=sender, args=((recv_pipe, send_pipe),))\n",
    "    p2 = Process(target=receiver, args=((recv_pipe, send_pipe),))\n",
    "    \n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    \n",
    "    p1.join()\n",
    "    send_pipe.send(\"END\")  # 通知接收者结束\n",
    "    p2.join()\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `Pipe`返回一对连接对象，默认情况下是双向的。在此例中，我们通过`duplex=False`创建一个单向管道。\n",
    "- `sender`进程通过管道发送消息，`receiver`进程接收消息并打印。\n",
    "- 这种方式适用于需要快速、双向通信的场景。\n",
    "\n",
    "### 应用案例6：利用共享内存进行大规模数据处理\n",
    "\n",
    "对于大规模数据处理任务，使用共享内存可以避免数据的不必要复制，提高处理效率。\n",
    "\n",
    "```python\n",
    "from multiprocessing import shared_memory, Process\n",
    "import numpy as np\n",
    "\n",
    "def modify_shared_array(shm_name, shape):\n",
    "    existing_shm = shared_memory.SharedMemory(name=shm_name)\n",
    "    arr = np.ndarray(shape, dtype=np.int, buffer=existing_shm.buf)\n",
    "    arr += 10  # 对共享数据进行修改\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    arr = np.array([1, 2, 3, 4, 5])\n",
    "    shm = shared_memory.SharedMemory(create=True, size=arr.nbytes)\n",
    "    np_array = np.ndarray(arr.shape, dtype=arr.dtype, buffer=shm.buf)\n",
    "    np_array[:] = arr[:]  # 复制数据到共享内存\n",
    "    \n",
    "    p = Process(target=modify_shared_array, args=(shm.name, arr.shape))\n",
    "    p.start()\n",
    "    p.join()\n",
    "    \n",
    "    print(np_array)  # 查看修改后的共享数据\n",
    "    shm.close()\n",
    "    shm.unlink()  # 释放共享内存\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- 使用`shared_memory`模块创建共享内存，该内存可以被多个进程访问。\n",
    "- 主进程创建共享内存并\n",
    "\n",
    "复制数据到其中，子进程读取共享内存中的数据，进行处理后，修改反映在主进程中。\n",
    "- 这种方法对于需要进程间共享大量数据的场景非常有效，特别是在数据科学和机器学习领域。\n",
    "\n",
    "这些案例展示了使用多进程解决复杂并发问题的能力，从动态任务分配、进程间通信到共享内存的使用，多进程编程为高性能计算和资源密集型任务提供了强大的解决方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f91e55",
   "metadata": {},
   "source": [
    "## 协程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a772f6",
   "metadata": {},
   "source": [
    "协程是一种用于并发编程的强大工具，特别是在I/O密集型应用和高并发需求的场景中。与传统的线程和进程相比，协程提供了更轻量级的并行执行能力。在Python中，协程的实现主要依赖于`asyncio`模块，它是Python 3.4及以上版本引入的标准库，用于编写单线程的并发代码。\n",
    "\n",
    "### 协程的基本概念\n",
    "\n",
    "协程，也称为微线程，是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。相较于线程，协程的一个重要优势是协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就自动恢复上一次调用的状态。\n",
    "\n",
    "### Python中的协程\n",
    "\n",
    "Python中的协程使用`async def`语句定义，通过`await`语句挂起协程的执行，直到等待的Future对象完成。使用`asyncio`模块可以创建事件循环，管理和调度协程。\n",
    "\n",
    "#### 定义协程\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    print('Hello')\n",
    "    await asyncio.sleep(1)\n",
    "    print('World')\n",
    "```\n",
    "\n",
    "`main`函数是一个协程，`asyncio.sleep(1)`暂停了协程的执行，让出控制权。\n",
    "\n",
    "#### 运行协程\n",
    "\n",
    "要运行协程，需要使用`asyncio.run()`函数或者在事件循环中调用它。\n",
    "\n",
    "```python\n",
    "asyncio.run(main())\n",
    "```\n",
    "\n",
    "或者\n",
    "\n",
    "```python\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(main())\n",
    "loop.close()\n",
    "```\n",
    "\n",
    "### 协程的优势\n",
    "\n",
    "协程相比于线程的优势在于：\n",
    "\n",
    "1. **更高的执行效率**：没有线程的切换开销，通过事件循环在单线程内实现并发。\n",
    "2. **不需要锁机制**：因为只有一个线程，不需要担心变量的同步问题，编程模型简单。\n",
    "3. **能够控制并发量**：在协程中可以控制同时运行的协程数量，有效地利用系统资源。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "协程适合用于I/O密集型和高并发的应用程序开发，如Web服务器、客户端网络连接处理、数据库操作等。\n",
    "\n",
    "### 示例：异步获取网页内容\n",
    "\n",
    "以下示例使用`aiohttp`库（一个支持异步请求的HTTP客户端）演示了如何异步获取网页内容。\n",
    "\n",
    "```python\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def fetch_page(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            print(f\"Response status: {response.status}\")\n",
    "            return await response.text()\n",
    "\n",
    "async def main():\n",
    "    html = await fetch_page('http://python.org')\n",
    "    print(html[:100])  # 打印网页的前100个字符\n",
    "\n",
    "asyncio.run(main())\n",
    "```\n",
    "\n",
    "请注意，`aiohttp`需要单独安装。\n",
    "\n",
    "通过这些基础知识和示例，我们可以看到协程在Python中如何实现以及它们在并发编程中的应用。协程的使用可以大大提高程序的性能和响应速度，尤其是在处理大量的I/O操作时。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40597139",
   "metadata": {},
   "source": [
    "探索协程的实际应用案例可以帮助我们深入理解其在解决并发问题上的能力。以下案例将展示如何利用协程进行高效的网络I/O操作、数据处理以及并发控制。\n",
    "\n",
    "### 应用案例1：并发下载多个网页\n",
    "\n",
    "假设我们需要下载多个网页内容，使用协程可以并发完成这些任务，显著提高效率。\n",
    "\n",
    "```python\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def download_page(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        print(f\"Downloading {url}\")\n",
    "        return await response.text()\n",
    "\n",
    "async def main(urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [asyncio.create_task(download_page(session, url)) for url in urls]\n",
    "        # 等待所有任务完成\n",
    "        for task in asyncio.as_completed(tasks):\n",
    "            # asyncio.as_completed(tasks) 按完成顺序返回结果\n",
    "            content = await task\n",
    "            print(f\"Page length: {len(content)}\")\n",
    "\n",
    "urls = [\n",
    "    \"http://python.org\",\n",
    "    \"http://pypi.org\",\n",
    "    \"http://docs.python.org/3/library/asyncio\",\n",
    "]\n",
    "\n",
    "asyncio.run(main(urls))\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- 使用`aiohttp.ClientSession()`创建一个会话来管理网络请求。\n",
    "- `download_page`是一个协程，负责下载单个网页内容。\n",
    "- 在`main`协程中，为每个URL创建一个下载任务，并使用`asyncio.create_task`将它们转换为任务。\n",
    "- 使用`asyncio.as_completed`并发执行任务，并按任务完成的顺序处理结果。\n",
    "\n",
    "### 应用案例2：异步处理大量数据\n",
    "\n",
    "利用协程，可以在处理大量数据时实现非阻塞I/O操作，比如从数据库异步读取数据。\n",
    "\n",
    "```python\n",
    "# 假设使用异步数据库库如aiomysql\n",
    "import aiomysql\n",
    "import asyncio\n",
    "\n",
    "async def fetch_data(loop):\n",
    "    async with aiomysql.create_pool(host='127.0.0.1', port=3306,\n",
    "                                     user='root', password='password',\n",
    "                                     db='mydb', loop=loop) as pool:\n",
    "        async with pool.acquire() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                await cur.execute(\"SELECT * FROM mytable\")\n",
    "                print(\"Data Fetched\")\n",
    "                return await cur.fetchall()\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "data = loop.run_until_complete(fetch_data(loop))\n",
    "print(data)\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- 使用`aiomysql`（一个支持协程的MySQL客户端库）进行数据库操作。\n",
    "- `fetch_data`协程中，使用`aiomysql.create_pool`创建一个连接池，然后异步获取数据。\n",
    "- `loop.run_until_complete`运行协程并等待结果。\n",
    "\n",
    "### 应用案例3：协程与任务控制\n",
    "\n",
    "协程配合任务（Task）可以实现复杂的并发控制，例如限制并发数量。\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "import random\n",
    "\n",
    "async def worker(name, queue):\n",
    "    while not queue.empty():\n",
    "        delay = await queue.get()\n",
    "        await asyncio.sleep(delay)\n",
    "        print(f\"{name} completed task, took {delay}s\")\n",
    "\n",
    "async def main():\n",
    "    queue = asyncio.Queue()\n",
    "    # 填充任务队列\n",
    "    for _ in range(10):\n",
    "        await queue.put(random.uniform(0.5, 1.5))\n",
    "\n",
    "    # 创建三个并发的worker\n",
    "    tasks = [asyncio.create_task(worker(f\"worker-{i}\", queue)) for i in range(3)]\n",
    "    \n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "asyncio.run(main())\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- 使用`asyncio.Queue`创建一个任务队列，并用随机延迟填充。\n",
    "- 创建多个`worker`协程并发执行任务，每个`worker`从队列中获取任务并异步等待。\n",
    "- `asyncio.gather`用于并发运行所有任务并等待它们全部完成。\n",
    "\n",
    "这些案例展示了协程在异步网络请求、数据处理和并发任务控制方面的实用性。通过合理利用`asyncio`和相关异步库，协程可以有效地解决并发编程中的各种挑战，提高程序的性能和响应速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d54196",
   "metadata": {},
   "source": [
    "深入探索更高级的协程应用案例可以帮助我们理解协程在处理复杂并发场景中的能力。以下案例将展示协程在实时数据处理、流控制以及资源管理等方面的高级应用。\n",
    "\n",
    "### 应用案例4：实时数据处理流\n",
    "\n",
    "在数据分析和网络应用中，经常需要实时地处理数据流。利用协程，我们可以高效地构建数据处理流水线。\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def data_source():\n",
    "    \"\"\"模拟数据源，异步生成数据\"\"\"\n",
    "    for i in range(1, 6):\n",
    "        yield i\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "async def data_processing_step1(data):\n",
    "    \"\"\"数据处理步骤1\"\"\"\n",
    "    return data * 2\n",
    "\n",
    "async def data_processing_step2(data):\n",
    "    \"\"\"数据处理步骤2\"\"\"\n",
    "    return data - 1\n",
    "\n",
    "async def data_consumer():\n",
    "    \"\"\"数据消费者\"\"\"\n",
    "    async for data in data_source():\n",
    "        # 连续处理数据\n",
    "        data = await data_processing_step1(data)\n",
    "        data = await data_processing_step2(data)\n",
    "        print(f\"Processed data: {data}\")\n",
    "\n",
    "asyncio.run(data_consumer())\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `data_source`是一个异步生成器，模拟实时数据源。\n",
    "- `data_processing_step1`和`data_processing_step2`分别代表处理数据的不同步骤。\n",
    "- `data_consumer`协程通过异步循环处理并消费数据。\n",
    "- 该模式适用于需要连续处理流式数据的场景，如实时数据分析或网络数据传输。\n",
    "\n",
    "### 应用案例5：异步上下文管理器和资源管理\n",
    "\n",
    "在处理文件、网络连接或数据库时，确保资源正确管理（如打开和关闭）是非常重要的。`asyncio`提供了异步上下文管理器来简化资源管理。\n",
    "\n",
    "```python\n",
    "import aiofiles\n",
    "\n",
    "async def process_file(filename):\n",
    "    async with aiofiles.open(filename, mode='r') as f:\n",
    "        contents = await f.read()\n",
    "    print(contents)\n",
    "\n",
    "asyncio.run(process_file('example.txt'))\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- `aiofiles`是一个支持异步文件操作的库。注意：`aiofiles`需要单独安装。\n",
    "- 使用`async with`语句异步打开文件，并在完成读取后自动关闭文件。\n",
    "- 这种异步资源管理模式适用于需要非阻塞I/O操作的场景，如高并发的网络应用或文件处理程序。\n",
    "\n",
    "### 应用案例6：流控制和背压处理\n",
    "\n",
    "在处理大量数据或高并发请求时，控制数据流的速率（背压处理）是避免系统过载的关键。协程可以帮助实现这一机制。\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def producer(queue):\n",
    "    \"\"\"生产者，产生数据\"\"\"\n",
    "    for i in range(10):\n",
    "        await queue.put(i)\n",
    "        print(f\"Produced {i}\")\n",
    "        await asyncio.sleep(1)  # 控制生产速率\n",
    "\n",
    "async def consumer(queue):\n",
    "    \"\"\"消费者，处理数据\"\"\"\n",
    "    while True:\n",
    "        item = await queue.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        print(f\"Consumed {item}\")\n",
    "        await asyncio.sleep(2)  # 控制消费速率\n",
    "\n",
    "async def main():\n",
    "    queue = asyncio.Queue(maxsize=5)  # 限制队列大小实现背压\n",
    "    prod_task = asyncio.create_task(producer(queue))\n",
    "    cons_task = asyncio.create_task(consumer(queue))\n",
    "    \n",
    "    await prod_task\n",
    "    await queue.put(None)  # 使用 None 作为结束信号\n",
    "    await cons_task\n",
    "\n",
    "asyncio.run(main())\n",
    "```\n",
    "\n",
    "**注解**:\n",
    "- 使用`asyncio.Queue`的`maxsize`参数限制队列大小，实现生产者和消费者之间的背压。\n",
    "- 生产者通过`await queue.put(i)`暂停，直到队列有空间。\n",
    "- 消费者通过`await queue.get()`从队列中取出数据，如果队列为空则暂停。\n",
    "- 这种模式适用于需要平衡生产者和消费者处理能力的场景，防止资源过载。\n",
    "\n",
    "通过这些高级应用案例，我们可以看到协程在异步数据处理、资源管理以及流控制方面的强大功能。正确使用协程和`asyncio`库可以显著提高程序的性能、可读性和可维护性，尤其适用于I/O密集型和高并发的应用场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f86377",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
