{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58cb765",
   "metadata": {},
   "source": [
    "## Gymnasium Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a145f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/deep-rl-class/blob/main/notebooks/unit1/unit1.ipynb\n",
    "\n",
    "# example for gymnasium\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "# First, we create our environment called LunarLander-v2\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "# Then we reset this environment\n",
    "observation, info = env.reset()\n",
    "\n",
    "for _ in range(20):\n",
    "  # Take a random action\n",
    "  action = env.action_space.sample()\n",
    "  print(\"Action taken:\", action)\n",
    "\n",
    "  # Do this action in the environment and get\n",
    "  # next_state, reward, terminated, truncated and info\n",
    "  observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "  # If the game is terminated (in our case we land, crashed) or truncated (timeout)\n",
    "  if terminated or truncated:\n",
    "      # Reset the environment\n",
    "      print(\"Environment is reset\")\n",
    "      observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e54e4",
   "metadata": {},
   "source": [
    "Create the LunarLander environment üåõ and understand how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8019b90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We create our environment with gym.make(\"\")\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "env.reset()\n",
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"Observation Space Shape\", env.observation_space.shape)\n",
    "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8dc2e",
   "metadata": {},
   "source": [
    "We see with Observation Space Shape (8,) that the observation is a vector of size 8, where each value contains different information about the lander:\n",
    "\n",
    "- Horizontal pad coordinate (x)\n",
    "- Vertical pad coordinate (y)\n",
    "- Horizontal speed (x)\n",
    "- Vertical speed (y)\n",
    "- Angle\n",
    "- Angular speed\n",
    "- If the left leg contact point has touched the land (boolean)\n",
    "- If the right leg contact point has touched the land (boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82fef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
    "print(\"Action Space Shape\", env.action_space.n)\n",
    "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d57338",
   "metadata": {},
   "source": [
    "## Create the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pip install 'stable-baselines3[extra]' to install sb.\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10_000)\n",
    "\n",
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    vec_env.render()\n",
    "    # VecEnv resets automatically\n",
    "    # if done:\n",
    "    #   obs = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b0e9d",
   "metadata": {},
   "source": [
    "Stable-Baselines3 is easy to set up:\n",
    "\n",
    "1Ô∏è‚É£ You create your environment (in our case it was done above)\n",
    "\n",
    "2Ô∏è‚É£ You define the model you want to use and instantiate this model model = PPO(\"MlpPolicy\")\n",
    "\n",
    "3Ô∏è‚É£ You train the agent with model.learn and define the number of training timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b8405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from huggingface_sb3 import package_to_hub\n",
    "\n",
    "model_name = \"ppo-LunarLander-v2\"\n",
    "\n",
    "# PLACE the variables you've just defined two cells above\n",
    "# Define the name of the environment\n",
    "env_id = \"LunarLander-v2\"\n",
    "\n",
    "# TODO: Define the model architecture we used\n",
    "model_architecture = \"PPO\"\n",
    "\n",
    "## Define a repo_id\n",
    "## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
    "## CHANGE WITH YOUR REPO ID\n",
    "repo_id = \"ThomasSimonini/ppo-LunarLander-v2\" # Change with your repo id, you can't push with mine üòÑ\n",
    "\n",
    "## Define the commit message\n",
    "commit_message = \"Upload PPO LunarLander-v2 trained agent\"\n",
    "\n",
    "# Create the evaluation env and set the render_mode=\"rgb_array\"\n",
    "eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
    "\n",
    "# PLACE the package_to_hub function you've just filled here\n",
    "package_to_hub(model=model, # Our trained model\n",
    "               model_name=model_name, # The name of our trained model\n",
    "               model_architecture=model_architecture, # The model architecture we used: in our case PPO\n",
    "               env_id=env_id, # Name of the environment\n",
    "               eval_env=eval_env, # Evaluation Environment\n",
    "               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
    "               commit_message=commit_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ff07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
