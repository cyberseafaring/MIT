{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa93825d",
   "metadata": {},
   "source": [
    "# 包装器 Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4f094",
   "metadata": {},
   "source": [
    "Gymnasium的包装器（Wrappers）提供了一种方便的方法来修改现有环境，而无需直接更改底层代码。使用包装器可以避免大量的模板代码，并使环境更加模块化。更重要的是，包装器可以被链式组合以叠加它们的效果，通过`gymnasium.make()`生成的大多数环境默认已经被包装。\n",
    "\n",
    "### 如何使用包装器\n",
    "\n",
    "要包装一个环境，首先需要初始化一个基础环境。然后，可以将这个环境连同（可能是可选的）参数一起传递给包装器的构造函数。\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RescaleAction\n",
    "\n",
    "base_env = gym.make(\"Hopper-v4\")\n",
    "print(base_env.action_space)  # Box(-1.0, 1.0, (3,), float32)\n",
    "\n",
    "wrapped_env = RescaleAction(base_env, min_action=0, max_action=1)\n",
    "print(wrapped_env.action_space)  # Box(0.0, 1.0, (3,), float32)\n",
    "```\n",
    "\n",
    "### 访问包装器下的环境\n",
    "\n",
    "可以使用`gymnasium.Wrapper.env`属性访问第一层包装器下的环境。由于`gymnasium.Wrapper`类继承自`gymnasium.Env`，`gymnasium.Wrapper.env`可能是另一个包装器。\n",
    "\n",
    "如果想要访问所有包装器层下的原始环境，可以使用`gymnasium.Wrapper.unwrapped`属性。如果环境已经是一个裸环境，`gymnasium.Wrapper.unwrapped`属性将直接返回自身。\n",
    "\n",
    "### 包装器可以做的常见操作\n",
    "\n",
    "1. **转换动作**：在应用到基础环境之前转换动作。\n",
    "2. **转换观察**：转换基础环境返回的观察。\n",
    "3. **转换奖励**：转换基础环境返回的奖励。\n",
    "\n",
    "这些转换可以通过继承`gymnasium.ActionWrapper`、`gymnasium.ObservationWrapper`或`gymnasium.RewardWrapper`并实现相应的转换方法来轻松实现。如果需要执行更复杂的任务，可以直接从`gymnasium.Wrapper`类继承。\n",
    "\n",
    "### 实现自定义包装器\n",
    "\n",
    "如果我们想实现自己的自定义包装器，可以参考官网doc相应的[教程](https://gymnasium.farama.org/main/api/wrappers/)。通过继承并重写`gymnasium.Wrapper`或其特定子类的方法，我们可以创建能够转换动作、观察或奖励的包装器，或者实现更复杂的环境修改。\n",
    "\n",
    "例如，如果你想创建一个包装器来归一化观察值：\n",
    "\n",
    "```python\n",
    "from gymnasium import ObservationWrapper\n",
    "import numpy as np\n",
    "\n",
    "class NormalizeObservation(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def observation(self, observation):\n",
    "        return np.array(observation) / self.observation_space.high\n",
    "\n",
    "# 使用自定义包装器\n",
    "env = NormalizeObservation(gym.make(\"Hopper-v4\"))\n",
    "```\n",
    "\n",
    "这个自定义包装器`NormalizeObservation`将观察值除以观察空间的最大值，从而实现观察值的归一化。通过这种方式，你可以根据需要对环境进行灵活的调整和扩展。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683b1b3",
   "metadata": {},
   "source": [
    "### class gymnasium.Wrapper(env: Env[ObsType, ActType])\n",
    "\n",
    "`gymnasium.Wrapper`类是一个基类，用于包装Gym环境（`gymnasium.Env`），允许对`step()`和`reset()`方法进行模块化的转换。这使得开发者能够在不改变底层环境代码的情况下，修改环境的行为。通过继承这个类，可以创建自定义的包装器，以适应特定的需求或实验设置。\n",
    "\n",
    "### 功能\n",
    "\n",
    "- **修改空间和奖励范围**：继承自`Wrapper`的包装器可以修改`action_space`、`observation_space`、`reward_range`和`metadata`属性，而不会改变底层环境的相应属性。\n",
    "- **改变方法行为**：`step()`和`reset()`方法的行为可以通过包装器来改变。这允许在环境执行动作或重置时添加额外的逻辑。\n",
    "- **指向包装环境的属性**：某些属性（如`spec`、`render_mode`、`np_random`）将指向包装器的环境，即指向`env`参数对应的属性。\n",
    "\n",
    "### 使用方法\n",
    "\n",
    "要创建一个自定义的环境包装器，我们需要继承`gymnasium.Wrapper`类，并且可以选择性地重写`step()`和`reset()`方法，以及其他想要修改的属性或方法。\n",
    "\n",
    "```python\n",
    "from gymnasium import Env, Wrapper\n",
    "\n",
    "class CustomWrapper(Wrapper):\n",
    "    def __init__(self, env: Env):\n",
    "        super().__init__(env)  # 不要忘记调用父类的构造函数\n",
    "    \n",
    "    def step(self, action):\n",
    "        # 在这里添加自定义的step逻辑\n",
    "        observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "        # 可以修改observation, reward, terminated, truncated, info\n",
    "        return observation, reward, terminated, truncated, info\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        # 在这里添加自定义的reset逻辑\n",
    "        observation = self.env.reset(**kwargs)\n",
    "        # 可以修改observation\n",
    "        return observation\n",
    "```\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 如果从`Wrapper`继承，不要忘记调用`super().__init__(env)`以确保环境被正确初始化。\n",
    "- 包装器提供了一种灵活的方式来扩展或修改环境的功能，但应注意不要在不影响原始环境语义的前提下进行修改。\n",
    "- 包装器可以被链式组合使用，但要确保这种组合的顺序不会导致意外的行为或性能问题。\n",
    "\n",
    "通过使用包装器，开发者可以轻松地为环境添加额外的特性或调整其行为，以满足不同的实验或训练需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46271900",
   "metadata": {},
   "source": [
    "## 使用`gymnasium.Wrapper`类的实例\n",
    "\n",
    "在这个示例中，我们将创建一个自定义的`gymnasium.Wrapper`类，该类将对环境的奖励进行修改，作为演示如何使用`Wrapper`来改变环境行为的方式。我们将创建一个包装器，该包装器将在原始奖励基础上添加一个常数值，以此来增加或减少环境的难度。\n",
    "\n",
    "### 定义自定义包装器\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "class RewardModifierWrapper(Wrapper):\n",
    "    def __init__(self, env, reward_increment):\n",
    "        super().__init__(env)\n",
    "        self.reward_increment = reward_increment\n",
    "    \n",
    "    def step(self, action):\n",
    "        observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "        # 修改奖励值\n",
    "        reward += self.reward_increment\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        return self.env.reset(**kwargs)\n",
    "```\n",
    "\n",
    "### 使用自定义包装器\n",
    "\n",
    "现在，我们将使用CartPole环境作为基础环境，并应用我们的`RewardModifierWrapper`来增加奖励值。\n",
    "\n",
    "```python\n",
    "# 创建基础环境\n",
    "base_env = gym.make('CartPole-v1')\n",
    "\n",
    "# 应用包装器，增加奖励值\n",
    "wrapped_env = RewardModifierWrapper(base_env, reward_increment=1.0)\n",
    "\n",
    "# 测试包装器\n",
    "observation = wrapped_env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    action = wrapped_env.action_space.sample()  # 随机选择一个动作\n",
    "    observation, reward, terminated, truncated, info = wrapped_env.step(action)\n",
    "    total_reward += reward\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        print(\"Total reward:\", total_reward)\n",
    "        break\n",
    "```\n",
    "\n",
    "这个示例演示了如何创建和使用一个自定义的`gymnasium.Wrapper`来修改环境奖励。通过`RewardModifierWrapper`类，我们在每个步骤的奖励上添加了一个常数值（在这个例子中是1.0），这使得获得的总奖励增加了。这种技术可以用于调整环境的难度，或者简单地用于实验，以观察不同奖励设置对学习算法的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc194046",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be297fa",
   "metadata": {},
   "source": [
    "### Wrapper.step(action: WrapperActType) → tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]\n",
    "\n",
    "`Wrapper.step`方法是`gymnasium.Wrapper`类中用于重写环境的`step`方法的函数。通过覆盖这个方法，开发者可以改变环境在执行动作后返回的数据。这为环境行为的自定义提供了极大的灵活性，允许开发者根据需要调整观察值、奖励、终止信号和其他信息。\n",
    "\n",
    "### 方法签名\n",
    "\n",
    "```python\n",
    "def step(self, action: WrapperActType) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n",
    "```\n",
    "\n",
    "- **参数**:\n",
    "  - `action` (`WrapperActType`): 环境应执行的动作。\n",
    "\n",
    "- **返回**:\n",
    "  - 一个元组，包含以下元素：\n",
    "    - `observation` (`WrapperObsType`): 环境的新观察值。\n",
    "    - `reward` (`SupportsFloat`): 执行动作后获得的奖励。\n",
    "    - `terminated` (`bool`): 表示环境是否已经达到一个终止状态。\n",
    "    - `truncated` (`bool`): 表示环境是否因为某种原因（如时间限制）而提前结束。\n",
    "    - `info` (`dict[str, Any]`): 包含额外信息的字典，可以用于调试或提供环境的其他元数据。\n",
    "\n",
    "### 示例用法\n",
    "\n",
    "假设我们想要创建一个包装器，该包装器将根据环境的当前状态来修改奖励值。如果观察值满足某个条件，我们将增加奖励；否则，我们将减少奖励。\n",
    "\n",
    "```python\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "class CustomRewardWrapper(Wrapper):\n",
    "    def step(self, action):\n",
    "        observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "        \n",
    "        # 根据观察值修改奖励\n",
    "        if observation[0] > 0.5:  # 假设观察值是一个数组，我们根据第一个元素的值来判断\n",
    "            reward += 1.0\n",
    "        else:\n",
    "            reward -= 1.0\n",
    "        \n",
    "        return observation, reward, terminated, truncated, info\n",
    "```\n",
    "\n",
    "这个示例展示了如何通过继承`gymnasium.Wrapper`并重写`step`方法，来根据观察值动态调整奖励。这种方法可以用于创建更复杂的环境包装器，以实现各种自定义行为和环境变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87cb4b",
   "metadata": {},
   "source": [
    "### Wrapper.reset(*, seed: int | None = None, options: dict[str, Any] | None = None) → tuple[WrapperObsType, dict[str, Any]]\n",
    "\n",
    "`Wrapper.reset`方法是`gymnasium.Wrapper`类中用于重写环境的`reset`方法的函数。这个方法在环境开始新的一轮（即新的episode）时被调用，可以被覆盖以改变环境在重置时返回的数据。这为初始化环境状态、设置随机种子或应用特定配置提供了一种灵活的方式。\n",
    "\n",
    "### 方法签名\n",
    "\n",
    "```python\n",
    "def reset(self, *, seed: int | None = None, options: dict[str, Any] | None = None) -> tuple[WrapperObsType, dict[str, Any]]:\n",
    "```\n",
    "\n",
    "- **参数**:\n",
    "  - `seed` (`int` | `None`): 用于环境随机数生成器的种子。如果提供，将用于确保环境的随机性具有确定性。\n",
    "  - `options` (`dict[str, Any]` | `None`): 包含环境特定配置的字典。这个参数允许传递额外的配置信息给环境的`reset`方法。\n",
    "\n",
    "- **返回**:\n",
    "  - 一个元组，包含以下元素：\n",
    "    - `observation` (`WrapperObsType`): 环境重置后的初始观察值。\n",
    "    - `info` (`dict[str, Any]`): 包含额外环境信息的字典，可以用于调试或提供环境的其他元数据。\n",
    "\n",
    "### 示例用法\n",
    "\n",
    "假设我们想要创建一个包装器，该包装器在环境重置时应用特定的初始配置，或者基于某些条件修改初始观察值。\n",
    "\n",
    "```python\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "class CustomResetWrapper(Wrapper):\n",
    "    def reset(self, *, seed: int = None, options: dict[str, Any] = None):\n",
    "        # 可以在这里添加重置环境之前的逻辑\n",
    "        observation, info = self.env.reset(seed=seed, options=options)\n",
    "        \n",
    "        # 根据需要修改初始观察值或info\n",
    "        # 例如，根据options中的某个配置修改观察值\n",
    "        if options and 'modify_observation' in options:\n",
    "            observation += 0.5  # 假设观察值是数值型或支持此类操作的数据结构\n",
    "        \n",
    "        return observation, info\n",
    "```\n",
    "\n",
    "这个示例展示了如何通过继承`gymnasium.Wrapper`并重写`reset`方法，来根据特定的条件或配置修改环境的初始观察值或其他信息。这种方法非常适用于需要根据不同实验条件初始化环境的情况，或者在环境重置时应用特定的设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227205a7",
   "metadata": {},
   "source": [
    "### Wrapper.render() → RenderFrame | list[RenderFrame] | None\n",
    "\n",
    "`Wrapper.render`方法是`gymnasium.Wrapper`类中用于重写环境的`render`方法的函数。通过覆盖这个方法，开发者可以改变环境在进行渲染时返回的数据。这提供了一个修改环境渲染行为的灵活接口，例如改变渲染模式、调整渲染的视觉效果，或者在渲染过程中添加额外的信息。\n",
    "\n",
    "### 方法签名\n",
    "\n",
    "```python\n",
    "def render(self) -> RenderFrame | list[RenderFrame] | None:\n",
    "```\n",
    "\n",
    "- **返回**:\n",
    "  - `RenderFrame`或`list[RenderFrame]`：环境渲染的帧或帧列表。这取决于环境和包装器的具体实现。有些环境可能返回单个渲染帧，而有些环境可能返回一系列帧（例如，当渲染整个动画序列时）。\n",
    "  - `None`：在某些情况下，如果环境的`render_mode`设置为不生成渲染输出，或者渲染方法被用于直接在屏幕上显示内容而不返回数据时，可能会返回`None`。\n",
    "\n",
    "### 示例用法\n",
    "\n",
    "假设我们想要创建一个包装器，该包装器在环境渲染时添加一些自定义文本或标记，以提供额外的调试信息或增强视觉效果。\n",
    "\n",
    "```python\n",
    "from gymnasium import Wrapper\n",
    "import cv2  # 假设使用OpenCV来修改渲染的图像\n",
    "\n",
    "class CustomRenderWrapper(Wrapper):\n",
    "    def render(self, *args, **kwargs):\n",
    "        frame = self.env.render(*args, **kwargs)  # 获取原始渲染帧\n",
    "        \n",
    "        if frame is not None:  # 确保帧不是None\n",
    "            # 使用OpenCV添加文本到帧上\n",
    "            cv2.putText(frame, 'Custom Text', (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                        (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        return frame\n",
    "```\n",
    "\n",
    "这个示例展示了如何通过继承`gymnasium.Wrapper`并重写`render`方法，来在环境渲染的帧上添加自定义文本。这种方法可以用于增强环境的可视化效果，或者在开发和调试过程中提供额外的信息。需要注意的是，示例中使用了`cv2.putText`函数来修改帧，这要求帧是以NumPy数组的形式返回的，并且你已经安装了`opencv-python`包。\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 当覆盖`render`方法时，应确保考虑到原始环境的`render_mode`设置，以及环境是返回渲染帧还是直接在屏幕上渲染。\n",
    "- 如果修改了渲染数据，要确保修改后的数据仍然符合环境预期的渲染格式和类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5184218a",
   "metadata": {},
   "source": [
    "### Wrapper.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611352f7",
   "metadata": {},
   "source": [
    "### classmethod Wrapper.wrapper_spec(**kwargs: Any) → WrapperSpec\n",
    "\n",
    "\n",
    "`Wrapper.wrapper_spec`是`gymnasium.Wrapper`类的一个类方法，用于生成包装器的规范（`WrapperSpec`）。这个规范定义了包装器的配置和参数，使得包装器的行为更加透明和可配置。通过使用`wrapper_spec`方法，可以在创建包装器实例时指定特定的参数和配置，从而定制包装器的行为。\n",
    "\n",
    "### 方法签名\n",
    "\n",
    "```python\n",
    "@classmethod\n",
    "def wrapper_spec(cls, **kwargs: Any) -> WrapperSpec:\n",
    "```\n",
    "\n",
    "- **参数**:\n",
    "  - `**kwargs`: 任意数量的关键字参数，用于指定包装器的配置和参数。\n",
    "\n",
    "- **返回**:\n",
    "  - `WrapperSpec`：一个包装器规范对象，包含了包装器的配置信息。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "`wrapper_spec`方法的主要用途是在定义自定义包装器时提供一种机制，通过这种机制，开发者可以指定包装器的行为和参数。这对于创建可复用、易于配置的环境包装器非常有用。\n",
    "\n",
    "### 示例\n",
    "\n",
    "假设我们想要创建一个自定义包装器，该包装器根据某个特定的配置参数来修改奖励。我们可以使用`wrapper_spec`方法来定义这个包装器的配置接口。\n",
    "\n",
    "```python\n",
    "from gymnasium import Wrapper, WrapperSpec\n",
    "\n",
    "class CustomRewardWrapper(Wrapper):\n",
    "    @classmethod\n",
    "    def wrapper_spec(cls, reward_multiplier=1.0):\n",
    "        \"\"\"\n",
    "        定义包装器的规范，包括奖励乘数的配置。\n",
    "        \"\"\"\n",
    "        return WrapperSpec(reward_multiplier=reward_multiplier)\n",
    "\n",
    "    def __init__(self, env, reward_multiplier=1.0):\n",
    "        super().__init__(env)\n",
    "        self.reward_multiplier = reward_multiplier\n",
    "    \n",
    "    def step(self, action):\n",
    "        observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "        # 使用配置的奖励乘数来修改奖励\n",
    "        reward *= self.reward_multiplier\n",
    "        return observation, reward, terminated, truncated, info\n",
    "```\n",
    "\n",
    "在这个示例中，`CustomRewardWrapper`包装器使用`wrapper_spec`类方法来定义一个名为`reward_multiplier`的配置参数。这个参数在包装器实例化时被用来调整奖励的大小。通过这种方式，`CustomRewardWrapper`的行为可以通过修改`reward_multiplier`参数来轻松定制。\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- `WrapperSpec`主要是一个概念工具，用于文档化和指定包装器的配置接口。其具体实现和使用可能依赖于`gymnasium`库的具体版本和上下文。\n",
    "- 在实际使用中，`WrapperSpec`的构造和使用细节可能有所不同。开发者应参考`gymnasium`的最新文档来了解如何在自己的项目中有效地使用这个功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3628b0",
   "metadata": {},
   "source": [
    "### Wrapper.get_wrapper_attr(name: str) → Any\n",
    "\n",
    "\n",
    "`Wrapper.get_wrapper_attr`方法允许从当前包装器或其下层环境中获取指定名称的属性。如果当前包装器对象中不存在指定名称的属性，则该方法会递归地在包装器链中向下查找，直到找到该属性为止。如果在整个包装器链中都找不到该属性，则会引发`AttributeError`。\n",
    "\n",
    "### 方法签名\n",
    "\n",
    "```python\n",
    "def get_wrapper_attr(self, name: str) -> Any:\n",
    "```\n",
    "\n",
    "- **参数**:\n",
    "  - `name` (`str`): 要获取的属性的名称。\n",
    "\n",
    "- **返回**:\n",
    "  - 任意类型 (`Any`): 属性的值。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "这个方法特别适用于在包装器链中访问深层环境的属性，而无需直接引用特定层的环境实例。这增加了代码的模块化和灵活性，特别是在处理复杂的环境包装器链时。\n",
    "\n",
    "### 示例\n",
    "\n",
    "假设我们有一个由多个包装器组成的环境，我们想要从最外层的包装器中获取一个位于较低层次的环境属性`special_attribute`。\n",
    "\n",
    "```python\n",
    "from gymnasium import Env, Wrapper\n",
    "\n",
    "class LowerWrapper(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.special_attribute = \"This is a special attribute from LowerWrapper\"\n",
    "\n",
    "class UpperWrapper(Wrapper):\n",
    "    pass\n",
    "\n",
    "# 创建环境和包装器链\n",
    "env = LowerWrapper(Env())\n",
    "wrapped_env = UpperWrapper(env)\n",
    "\n",
    "# 从上层包装器中获取下层包装器的属性\n",
    "special_attr_value = wrapped_env.get_wrapper_attr('special_attribute')\n",
    "print(special_attr_value)  # 输出: This is a special attribute from LowerWrapper\n",
    "```\n",
    "\n",
    "在这个示例中，`UpperWrapper`没有定义`special_attribute`属性，所以`get_wrapper_attr`方法会在包装器链中向下查找，直到在`LowerWrapper`中找到该属性，并返回其值。\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 使用`get_wrapper_attr`方法可以有效地解耦包装器之间的依赖关系，但应当注意确保所请求的属性名称在环境或包装器链中是唯一的，以避免潜在的名称冲突。\n",
    "- 如果属性名不存在于任何包装器或环境中，将会引发`AttributeError`。因此，可能需要在使用此方法时进行适当的异常处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa0951",
   "metadata": {},
   "source": [
    "### Wrapper.set_wrapper_attr(name: str, value: Any)\n",
    "\n",
    "`Wrapper.set_wrapper_attr`方法允许在当前包装器或其下层环境中设置指定名称的属性。如果当前包装器对象或其任一下层环境已经定义了该名称的属性，则该方法会更新该属性的值。这个方法提供了一种修改环境属性的灵活方式，而无需直接访问或修改环境的内部实现。\n",
    "\n",
    "### 方法签名\n",
    "\n",
    "```python\n",
    "def set_wrapper_attr(self, name: str, value: Any):\n",
    "```\n",
    "\n",
    "- **参数**:\n",
    "  - `name` (`str`): 要设置的属性的名称。\n",
    "  - `value` (`Any`): 新的属性值。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "这个方法特别适用于在环境的包装器链中修改属性，尤其是当你需要调整下层环境的某些行为或状态，但又不想破坏包装器的封装性时。\n",
    "\n",
    "### 示例\n",
    "\n",
    "假设我们有一个包装器链，我们想要修改其中某个已经定义的属性`special_attribute`的值。\n",
    "\n",
    "```python\n",
    "from gymnasium import Env, Wrapper\n",
    "\n",
    "class CustomWrapper(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.special_attribute = \"Initial value\"\n",
    "\n",
    "# 创建环境和包装器\n",
    "env = Env()\n",
    "wrapped_env = CustomWrapper(env)\n",
    "\n",
    "# 设置包装器的属性\n",
    "wrapped_env.set_wrapper_attr('special_attribute', \"New value\")\n",
    "\n",
    "# 验证属性值已经改变\n",
    "print(wrapped_env.special_attribute)  # 输出: New value\n",
    "```\n",
    "\n",
    "在这个示例中，`CustomWrapper`包装器定义了一个名为`special_attribute`的属性，并通过`set_wrapper_attr`方法更新了这个属性的值。如果这个属性在包装器链的更低层已经存在，并且当前层没有定义该属性，则该方法会在包装器链中向下查找，并更新最先找到的匹配属性的值。\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 使用`set_wrapper_attr`方法时，如果在包装器链中没有找到已经定义的属性，该方法不会创建新属性。这意味着，你需要确保属性名在调用`set_wrapper_attr`之前已经在某个层级上被定义。\n",
    "- 这种方法可以有效地管理和修改环境的状态或配置，但应谨慎使用，以避免不小心破坏环境的预期行为或产生意外的副作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86ebb79",
   "metadata": {},
   "source": [
    "## Attributes 属性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c5e583",
   "metadata": {},
   "source": [
    "### Wrapper.env\n",
    "\n",
    "`Wrapper.env`属性提供了对当前包装器直接下层的环境（可能是另一个包装器或原始环境）的访问。这个属性是理解和使用Gym包装器架构的核心部分，因为它允许开发者在包装器链中导航，访问和修改下层环境的属性和方法。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "- **访问下层环境**：当你需要获取下层环境的特定信息或调用其方法时，可以通过`env`属性直接访问。\n",
    "- **修改下层环境状态**：在某些情况下，你可能需要修改下层环境的状态或属性，这可以通过`env`属性直接实现。\n",
    "- **链式包装器**：在创建多层包装器时，`env`属性用于引用被当前包装器包装的环境。\n",
    "\n",
    "### 示例\n",
    "\n",
    "假设我们有一个环境被多个包装器包装，我们想要从最外层包装器中访问并调用下层环境的一个方法。\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "class CustomWrapper(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def special_method(self):\n",
    "        print(\"Called a method on CustomWrapper.\")\n",
    "\n",
    "# 创建原始环境和包装器链\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "wrapped_env = CustomWrapper(env)\n",
    "\n",
    "# 通过Wrapper.env属性访问下层环境\n",
    "print(wrapped_env.env)  # 输出原始环境的表示\n",
    "\n",
    "# 直接调用下层环境的方法\n",
    "wrapped_env.env.reset()\n",
    "```\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 当使用`Wrapper.env`属性时，应注意不要破坏环境的封装性和独立性。理想情况下，包装器应该通过重写方法和属性来间接影响下层环境，而不是直接修改下层环境的内部状态。\n",
    "- 要获取最底层的原始环境，可以使用`Wrapper.unwrapped`属性，而不是多次使用`env`属性来逐层向下访问。\n",
    "\n",
    "通过这种方式，Gym的包装器架构提供了一种强大而灵活的机制来增强和修改环境的行为，同时保持代码的清晰和模块化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa3719",
   "metadata": {},
   "source": [
    "### property Wrapper.action_space: spaces.Space[ActType] | spaces.Space[WrapperActType]\n",
    "\n",
    "`Wrapper.action_space`属性是`gymnasium.Wrapper`类的一个属性，用于返回当前环境（或包装器）的动作空间。这个属性非常重要，因为它定义了在环境中可执行的所有动作的集合。\n",
    "\n",
    "### 功能\n",
    "\n",
    "- **未覆盖时**：如果没有通过包装器修改动作空间，则`Wrapper.action_space`属性将返回被包装环境（`env`）的`action_space`。\n",
    "- **覆盖后**：如果在包装器中覆盖了动作空间（例如，通过修改动作空间的类型或范围），则`Wrapper.action_space`属性将返回修改后的动作空间。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "- **动作空间转换**：当需要将环境的动作空间从一种形式转换为另一种形式时，可以通过创建自定义包装器来实现。例如，将离散动作空间转换为连续动作空间。\n",
    "- **动作空间扩展或限制**：在某些情况下，可能需要扩展或限制原始环境的动作空间，以适应特定的训练需求或实验设计。\n",
    "\n",
    "### 示例\n",
    "\n",
    "下面的示例展示了如何创建一个自定义包装器来修改原始环境的动作空间：\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "from gymnasium import Wrapper\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "\n",
    "class ActionSpaceModifier(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        # 假设我们想将原始环境的动作空间修改为连续动作空间\n",
    "        self.action_space = Box(low=-1.0, high=1.0, shape=(1,), dtype=\"float32\")\n",
    "    \n",
    "    # 可以在这里添加覆盖step方法的代码，以处理新的动作空间\n",
    "\n",
    "# 创建原始环境\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "print(\"Original action space:\", env.action_space)\n",
    "\n",
    "# 应用自定义包装器\n",
    "modified_env = ActionSpaceModifier(env)\n",
    "print(\"Modified action space:\", modified_env.action_space)\n",
    "```\n",
    "\n",
    "在这个示例中，我们创建了`ActionSpaceModifier`包装器来将原始的`CartPole-v1`环境的动作空间（原本是离散的）修改为连续动作空间。通过修改`self.action_space`属性，我们定义了新的动作空间范围和类型。\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 修改动作空间时，需要确保包装器中的`step`方法能够正确处理新的动作空间类型和格式。\n",
    "- 当使用自定义包装器修改动作空间时，也要考虑到如何处理环境返回的观察值和奖励，以确保它们与新的动作空间兼容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566a0d3e",
   "metadata": {},
   "source": [
    "### property Wrapper.observation_space: spaces.Space[ObsType] | spaces.Space[WrapperObsType]\n",
    "\n",
    "\n",
    "`Wrapper.observation_space`属性是`gymnasium.Wrapper`类的一个属性，用于返回当前环境（或包装器）的观察空间。这个属性定义了环境可能返回的所有观察值的集合，是理解和使用环境的关键部分。\n",
    "\n",
    "### 功能\n",
    "\n",
    "- **未覆盖时**：如果包装器没有修改观察空间，则`Wrapper.observation_space`属性将返回被包装环境（`env`）的`observation_space`。\n",
    "- **覆盖后**：如果在包装器中覆盖了观察空间（例如，通过修改观察空间的类型或范围），则`Wrapper.observation_space`属性将返回修改后的观察空间。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "- **观察空间转换**：当需要将环境的观察空间从一种形式转换为另一种形式时，可以通过创建自定义包装器来实现。例如，将图像观察空间转换为灰度或缩小尺寸。\n",
    "- **观察空间扩展或限制**：在某些情况下，可能需要扩展或限制原始环境的观察空间，以适应特定的训练需求或实验设计。\n",
    "\n",
    "### 示例\n",
    "\n",
    "下面的示例展示了如何创建一个自定义包装器来修改原始环境的观察空间：\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "from gymnasium import Wrapper\n",
    "from gymnasium.spaces import Box\n",
    "\n",
    "class ObservationSpaceModifier(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        # 假设我们想将原始环境的观察空间修改为具有不同形状的空间\n",
    "        self.observation_space = Box(low=0, high=255, shape=(64, 64, 3), dtype=\"uint8\")\n",
    "    \n",
    "    # 可以在这里添加覆盖reset和step方法的代码，以处理新的观察空间\n",
    "\n",
    "# 创建原始环境\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "print(\"Original observation space:\", env.observation_space)\n",
    "\n",
    "# 应用自定义包装器\n",
    "modified_env = ObservationSpaceModifier(env)\n",
    "print(\"Modified observation space:\", modified_env.observation_space)\n",
    "```\n",
    "\n",
    "在这个示例中，我们创建了`ObservationSpaceModifier`包装器来将原始的`CartPole-v1`环境的观察空间修改为具有不同形状（64x64x3）的空间，可能代表一个缩放的RGB图像。通过修改`self.observation_space`属性，我们定义了新的观察空间范围和形状。\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 修改观察空间时，需要确保包装器中的`reset`和`step`方法能够正确处理新的观察空间类型和格式。\n",
    "- 当使用自定义包装器修改观察空间时，也要考虑到如何处理环境返回的动作和奖励，以确保它们与新的观察空间兼容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97f202",
   "metadata": {},
   "source": [
    "### property Wrapper.spec: EnvSpec | None\n",
    "\n",
    "\n",
    "`Wrapper.spec`属性提供了对当前环境或包装器`spec`属性的访问。这个属性通常包含了环境的规格信息，比如环境的ID、最大步数（如果有时间限制的话）、奖励范围等。这些信息对于了解和使用环境至关重要，尤其是在需要根据环境的特定参数来调整策略或算法时。\n",
    "\n",
    "### 功能\n",
    "\n",
    "- **环境规格**：`spec`属性通常来自原始环境，并通过包装器链传递。它包含了环境的元数据和配置信息。\n",
    "- **包装器规格**：如果包装器继承自`EzPickle`（一个用于简化pickle操作的工具），`spec`属性还可能包含`WrapperSpec`信息，这是由包装器添加的额外规格信息。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "- **环境信息获取**：在实验设置或算法初始化时，可能需要查询环境的特定规格，如环境ID或奖励范围，以确保算法正确适配环境特性。\n",
    "- **动态环境配置**：在需要根据环境规格动态配置策略参数或学习率等算法设置时，`spec`属性提供了必要的信息来源。\n",
    "\n",
    "### 示例\n",
    "\n",
    "假设我们有一个环境`env`，我们想要获取它的`spec`属性来了解环境的基本规格。\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "\n",
    "# 创建环境\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# 获取环境规格\n",
    "env_spec = env.spec\n",
    "\n",
    "print(\"Environment ID:\", env_spec.id)\n",
    "print(\"Max episode steps:\", env_spec.max_episode_steps)\n",
    "print(\"Reward range:\", env_spec.reward_threshold)\n",
    "```\n",
    "\n",
    "如果环境被一个或多个包装器包装，我们同样可以通过`spec`属性访问基础环境的规格信息。\n",
    "\n",
    "```python\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "class CustomWrapper(Wrapper):\n",
    "    pass\n",
    "\n",
    "# 应用包装器\n",
    "wrapped_env = CustomWrapper(env)\n",
    "\n",
    "# 通过包装器获取环境规格\n",
    "wrapped_env_spec = wrapped_env.spec\n",
    "\n",
    "print(\"Wrapped Environment ID:\", wrapped_env_spec.id)\n",
    "```\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 不是所有环境都会定义`spec`属性，或者在`spec`中提供完整的规格信息。因此，在使用这个属性时，应当检查其是否存在并处理潜在的`None`值。\n",
    "- 如果包装器修改了环境的基本行为（如动作空间、观察空间或奖励机制），则应当在包装器中适当更新或注明这些变化，尽管这些变化可能不直接反映在`spec`属性中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c2441",
   "metadata": {},
   "source": [
    "### property Wrapper.metadata: dict[str, Any]\n",
    "\n",
    "`Wrapper.metadata`属性提供了对当前环境或包装器中的`metadata`属性的访问。这个属性包含了有关环境的额外信息，比如环境支持的渲染模式、是否支持人类可读的渲染等。`metadata`通常是一个字典，其中包含了一系列键值对，描述了环境的各种特性和能力。\n",
    "\n",
    "### 功能\n",
    "\n",
    "- **环境信息**：`metadata`属性提供了关于环境特性的详细信息，这有助于开发者了解环境的能力和限制。\n",
    "- **渲染模式**：常见的`metadata`包含`render_modes`键，列出了环境支持的所有渲染模式，如`'human'`、`'rgb_array'`等。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "- **确定渲染能力**：在设计实验或开发与环境交互的接口时，可能需要根据环境支持的渲染模式来调整代码或用户界面。\n",
    "- **环境能力查询**：在使用自动化脚本或框架管理多个环境时，`metadata`提供了一种方法来查询环境的特性，以便根据这些信息自动配置实验。\n",
    "\n",
    "### 示例\n",
    "\n",
    "假设我们想要查询环境支持的渲染模式，并基于该信息决定是否以人类可观看的模式渲染环境。\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "\n",
    "# 创建环境\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# 查询环境metadata\n",
    "metadata = env.metadata\n",
    "\n",
    "# 检查环境支持的渲染模式\n",
    "if 'human' in metadata.get('render_modes', []):\n",
    "    print(\"Environment supports human-readable rendering.\")\n",
    "    # 可以安全地以人类可观看的模式渲染环境\n",
    "    env.render(mode='human')\n",
    "else:\n",
    "    print(\"Human-readable rendering is not supported.\")\n",
    "```\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 不是所有环境都会在`metadata`中提供相同类型或数量的信息。开发者在使用`metadata`中的信息时应当检查键是否存在，并处理键不存在的情况。\n",
    "- 在通过包装器链访问`metadata`时，如果某个包装器修改了环境的某些特性（例如，添加或移除渲染模式），那么这个包装器应该相应地更新`metadata`属性，以确保`metadata`反映了当前环境的正确状态。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2bed1",
   "metadata": {},
   "source": [
    "### property Wrapper.np_random: Generator\n",
    "\n",
    "\n",
    "`Wrapper.np_random`属性提供了对环境中`numpy`随机数生成器（`np_random`）的访问。这个随机数生成器通常用于环境内部以保证各种随机事件（例如，初始状态的选择、随机干扰的引入等）的生成是可重复的，从而允许实验的可复现性。\n",
    "\n",
    "### 功能\n",
    "\n",
    "- **随机数生成**：`np_random`属性是一个`numpy`的随机数生成器实例，用于环境中所有需要随机性的地方。\n",
    "- **可重复性**：通过设置随机数生成器的种子（seed），可以确保环境的随机性具有确定性，从而使实验结果可重复。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "- **环境随机性控制**：在进行实验时，为了确保结果的可重复性，经常需要设置环境的随机种子。\n",
    "- **自定义随机事件**：在开发自定义环境或包装器时，可能需要生成自定义的随机事件，`np_random`提供了生成这些事件的基础设施。\n",
    "\n",
    "### 示例\n",
    "\n",
    "假设我们正在使用一个环境，并希望确保它的随机性是可重复的，我们可以通过获取`np_random`属性并设置种子来实现。\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "\n",
    "# 创建环境\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# 设置环境的随机种子\n",
    "env.seed(42)\n",
    "\n",
    "# 访问环境的np_random属性\n",
    "np_random = env.np_random\n",
    "\n",
    "# 使用np_random生成一个随机数\n",
    "random_number = np_random.uniform(0, 1)\n",
    "print(\"Generated random number:\", random_number)\n",
    "```\n",
    "\n",
    "在这个示例中，我们首先通过调用`env.seed(42)`设置了环境的随机种子，这确保了`env`中所有随机事件的生成是可重复的。然后，我们通过访问`env.np_random`获取了环境的随机数生成器，并使用它来生成了一个随机数。\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 当使用多个环境或进行并行实验时，每个环境应该有一个独立的随机数生成器实例，以避免随机状态在环境之间的不必要共享。\n",
    "- 在创建自定义包装器时，如果包装器引入了新的随机事件，应当使用环境提供的`np_random`随机数生成器来保持整体实验的可控性和可重复性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6134c80",
   "metadata": {},
   "source": [
    "### property Wrapper.unwrapped: Env[ObsType, ActType]\n",
    "\n",
    "`Wrapper.unwrapped`属性是`gymnasium.Wrapper`类中的一个属性，用于返回包装器链最底层的原始环境。这个属性非常有用，因为它允许开发者直接访问并与底层环境进行交互，而无需逐层通过包装器链进行导航。这在需要直接访问原始环境的特定方法或属性时特别方便。\n",
    "\n",
    "### 功能\n",
    "\n",
    "- **访问原始环境**：无论环境被多少层包装器包装，`unwrapped`属性都可以直接返回最底层的原始环境（即，没有被任何包装器修改的环境）。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "- **直接操作原始环境**：在某些高级用例中，可能需要直接访问和操作原始环境，而不是通过包装器修改后的版本。例如，访问原始环境的某些未公开的方法或属性，或者在进行环境分析和调试时。\n",
    "- **绕过包装器的修改**：如果包装器链中的某些包装器修改了环境的行为或属性，而这些修改对于特定的任务或分析是不希望的，使用`unwrapped`属性可以直接与原始环境交互，绕过这些修改。\n",
    "\n",
    "### 示例\n",
    "\n",
    "假设我们有一个环境，它被多个包装器包装。现在，我们想要直接访问这个环境的某个原始方法，我们可以使用`unwrapped`属性来实现。\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "class CustomWrapper(Wrapper):\n",
    "    pass\n",
    "\n",
    "# 创建原始环境\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# 应用包装器\n",
    "wrapped_env = CustomWrapper(env)\n",
    "\n",
    "# 直接访问最底层的原始环境\n",
    "base_env = wrapped_env.unwrapped\n",
    "\n",
    "# 假设原始环境有一个特定的方法`original_method`，我们可以直接调用它\n",
    "# base_env.original_method()\n",
    "```\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 使用`unwrapped`属性时，应当明确为什么需要绕过包装器链。在大多数情况下，与环境的交互应该通过包装器链进行，以确保所有的修改和增强都得到应用。\n",
    "- 直接访问和修改原始环境可能会导致与包装器链中的修改不一致的行为，因此需要谨慎使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a911c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d53594c",
   "metadata": {},
   "source": [
    "# 包装器列表 List of Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2df024",
   "metadata": {},
   "source": [
    "下面是`gymnasium`库提供的常用包装器的列表，以及它们详细的中文描述：\n",
    "\n",
    "| 名称 | 描述 |\n",
    "|:-----|:-----|\n",
    "| AtariPreprocessing | 为Atari环境实现了常见的预处理技术（不包括帧堆叠）。 |\n",
    "| Autoreset | 当达到终止或截断状态时，被包装的环境会自动重置。 |\n",
    "| ClipAction | 将传递给step的动作剪辑到环境的`action_space`范围内。 |\n",
    "| ClipReward | 将环境的奖励剪辑到上下界之间。 |\n",
    "| DelayObservation | 为环境返回的观察值添加延迟。 |\n",
    "| DtypeObservation | 修改观察数组的数据类型为指定的dtype。 |\n",
    "| FilterObservation | 通过一组键或索引过滤Dict或Tuple观察空间。 |\n",
    "| FlattenObservation | 将环境的观察空间以及来自reset和step函数的每个观察值展平。 |\n",
    "| FrameStackObservation | 以滚动方式堆叠最后N个时间步的观察值。 |\n",
    "| GrayscaleObservation | 将通过reset和step计算得到的图像观察值从RGB转换为灰度。 |\n",
    "| HumanRendering | 对支持“rgb_array”渲染的环境，提供类似人类的渲染。 |\n",
    "| JaxToNumpy | 包装基于Jax的环境，使其可以与NumPy数组交互。 |\n",
    "| JaxToTorch | 包装基于Jax的环境，使其可以与PyTorch张量交互。 |\n",
    "| MaxAndSkipObservation | 跳过第N帧（观察值），并返回最后两个观察值之间的最大值。 |\n",
    "| NormalizeObservation | 将观察值标准化，使其以均值为中心，具有单位方差。 |\n",
    "| NormalizeReward | 标准化即时奖励，使其指数移动平均具有固定方差。 |\n",
    "| NumpyToTorch | 包装基于NumPy的环境，使其可以与PyTorch张量交互。 |\n",
    "| OrderEnforcing | 如果在render之前调用了step或render，则会产生错误。 |\n",
    "| PassiveEnvChecker | 环绕step、reset和render函数的被动环境检查包装器，检查它们是否遵循gymnasium的API。 |\n",
    "| RecordEpisodeStatistics | 这个包装器会跟踪累计奖励和剧集长度。 |\n",
    "| RecordVideo | 使用环境的render函数记录环境剧集的视频。 |\n",
    "| RenderCollection | 收集环境的渲染帧，使render返回`list[RenderedFrame]`。 |\n",
    "| AddRenderObservation | 在环境的观察值中包含渲染的观察值。 |\n",
    "| RescaleAction | 线性（仿射）重新调整环境的Box动作空间的范围到`[min_action, max_action]`之间。 |\n",
    "| RescaleObservation | 线性（仿射）重新调整环境的Box观察空间的范围到`[min_obs, max_obs]`之间。 |\n",
    "| ReshapeObservation | 将基于数组的观察值重新塑形为指定的形状。 |\n",
    "| ResizeObservation | 使用OpenCV将图像观察值调整为指定的形状。 |\n",
    "| StickyAction | 添加一个概率，使得动作在同一step函数中重复。 |\n",
    "| TimeAwareObservation | 将观察值增加了一个剧集内所采取的时间步数。 |\n",
    "| TimeLimit | 通过截断环境来限制环境的步数，如果超过了最大时间步数。 |\n",
    "| TransformAction | 在将修改后的值传递给环境step函数之前，对动作应用一个函数。 |\n",
    "| TransformObservation | 对来自环境的reset和step的观察值应用一个函数，然后传回给用户。 |\n",
    "| TransformReward | 对来自环境的step的奖励应用一个函数。 |\n",
    "\n",
    "这些包装器为开发者提供了一种方便的方式来修改和增强环境的行为，无需直接修改环境本身的代码。通过使用这些包装器，可以轻松实现诸如观察值和动作的修改、奖励的调整、环境的渲染和记录等功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2144de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e096b162",
   "metadata": {},
   "source": [
    "## Vector only Wrappers 仅用于矢量环境的包装器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393b596",
   "metadata": {},
   "source": [
    "下面是`gymnasium`库提供的针对向量化环境处理的包装器列表，以及它们详细的中文描述：\n",
    "\n",
    "| 名称 | 描述 |\n",
    "|:----- |:----- |\n",
    "| DictInfoToList | 将向量化环境的`infos`从字典格式转换为`List[dict]`格式。 |\n",
    "| VectorizeTransformAction | 将单代理（单个智能体）的动作转换包装器向量化，用于向量环境。 |\n",
    "| VectorizeTransformObservation | 将单代理的观察转换包装器向量化，用于向量环境。 |\n",
    "| VectorizeTransformReward | 将单代理的奖励转换包装器向量化，用于向量环境。 |\n",
    "\n",
    "这些包装器主要用于处理并行或向量化环境，其中同时运行多个环境实例。它们提供了一种方便的方式来扩展单代理环境的包装器，使其可以用于处理多代理（多个环境实例）的情况。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "- **向量化环境信息转换**：`DictInfoToList`包装器可以将来自多个并行环境实例的信息（`infos`）从字典形式转换为列表形式，便于后续处理和分析。\n",
    "- **动作、观察值和奖励的向量化处理**：`VectorizeTransformAction`、`VectorizeTransformObservation`和`VectorizeTransformReward`包装器可以将针对单个环境实例的动作、观察值和奖励的转换逻辑应用于向量化环境，从而实现对并行环境的同步处理。\n",
    "\n",
    "### 示例\n",
    "\n",
    "假设我们有一个单代理环境的自定义奖励转换包装器，我们想要将其应用于向量化环境：\n",
    "\n",
    "```python\n",
    "from gymnasium import Env, spaces\n",
    "from gymnasium.wrappers import TransformReward\n",
    "from gymnasium.vector.utils import VectorizeTransformReward\n",
    "\n",
    "class CustomRewardWrapper(TransformReward):\n",
    "    def transform_reward(self, reward):\n",
    "        # 自定义奖励转换逻辑\n",
    "        return reward + 1.0\n",
    "\n",
    "# 假设env是一个Env的实例\n",
    "env = Env()\n",
    "\n",
    "# 应用单代理奖励转换包装器\n",
    "single_agent_wrapped_env = CustomRewardWrapper(env)\n",
    "\n",
    "# 将单代理奖励转换包装器向量化\n",
    "vectorized_wrapped_env = VectorizeTransformReward(single_agent_wrapped_env)\n",
    "```\n",
    "\n",
    "在这个示例中，我们首先创建了一个`CustomRewardWrapper`来实现奖励的自定义转换逻辑。然后，我们使用`VectorizeTransformReward`包装器将这个自定义奖励转换逻辑向量化，使其可以应用于向量化环境。\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "- 使用这些向量化包装器时，需要确保原始的单代理包装器逻辑适用于向量化环境的每个实例。\n",
    "- 向量化环境通常用于并行化训练和评估，可以显著提高处理效率，但也需要注意数据结构和处理逻辑的正确转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66efed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95ca614e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
